\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro

    \usepackage{iftex}
    \ifPDFTeX
        \usepackage[T1]{fontenc}
        \IfFileExists{alphabeta.sty}{
              \usepackage{alphabeta}
          }{
              \usepackage[mathletters]{ucs}
              \usepackage[utf8x]{inputenc}
          }
    \else
        \usepackage{fontspec}
        \usepackage{unicode-math}
    \fi

    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage{array}     % table support for pandoc >= 2.11.3
    \usepackage{calc}      % table minipage width calculation for pandoc >= 2.11.1
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{soul}      % strikethrough (\st) support for pandoc >= 3.0.0
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}

    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}


    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{Stroke\_and\_Life\_Expectancy}
    
    
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.61,0.40,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.80,0.25,0.22}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.46,0.46,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.41,0.47,0.13}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.36,0.12}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.52,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{0.89,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb.
    \makeatletter
        \newbox\Wrappedcontinuationbox
        \newbox\Wrappedvisiblespacebox
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}}
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}}
        \newcommand*\Wrappedcontinuationindent {3ex }
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox}
        % Take advantage of the already applied Pygments mark-up to insert
        % potential linebreaks for TeX processing.
        %        {, <, #, %, $, ' and ": go to next line.
        %        _, }, ^, &, >, - and ~: stay at end of broken line.
        % Use of \textquotesingle for straight quote.
        \newcommand*\Wrappedbreaksatspecials {%
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}%
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}%
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}%
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}%
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}%
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}%
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}%
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}%
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}%
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}%
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}%
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}%
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}%
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}%
        }
        % Some characters . , ; ? ! / are not pygmentized.
        % This macro makes them "active" and they will insert potential linebreaks
        \newcommand*\Wrappedbreaksatpunct {%
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}%
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}%
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}%
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}%
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}%
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}%
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}%
            \catcode`\.\active
            \catcode`\,\active
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active
            \lccode`\~`\~
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%

        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}

    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Stroke and Life Expectancy Qualitative and Quantitative Analysis}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} Author: Scott Eugley}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} Date: 12/15/2023}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Load in datasets and libraries}

\PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{os}
\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
\PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{linear\PYZus{}model} \PY{k+kn}{import} \PY{n}{LogisticRegression}\PY{p}{,} \PY{n}{LinearRegression}\PY{p}{,} \PY{n}{Lasso}\PY{p}{,} \PY{n}{Ridge}\PY{p}{,} \PY{n}{LassoCV}\PY{p}{,} \PY{n}{RidgeCV}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k+kn}{import} \PY{n}{confusion\PYZus{}matrix}\PY{p}{,} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{,} \PY{n}{accuracy\PYZus{}score}\PY{p}{,} \PY{n}{mean\PYZus{}absolute\PYZus{}error}\PY{p}{,} \PY{n}{roc\PYZus{}curve}\PY{p}{,} \PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{,}\PY{n}{precision\PYZus{}recall\PYZus{}curve}\PY{p}{,} \PY{n}{auc}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{decomposition} \PY{k+kn}{import} \PY{n}{PCA}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{cross\PYZus{}decomposition} \PY{k+kn}{import} \PY{n}{PLSRegression}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{pipeline} \PY{k+kn}{import} \PY{n}{Pipeline}
\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{api} \PY{k}{as} \PY{n+nn}{sm}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{neighbors} \PY{k+kn}{import} \PY{n}{KNeighborsClassifier}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{discriminant\PYZus{}analysis} \PY{k+kn}{import} \PY{n}{LinearDiscriminantAnalysis}\PY{p}{,} \PY{n}{QuadraticDiscriminantAnalysis}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{tree} \PY{k+kn}{import} \PY{n}{DecisionTreeClassifier}\PY{p}{,} \PY{n}{plot\PYZus{}tree}\PY{p}{,} \PY{n}{DecisionTreeRegressor}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k+kn}{import} \PY{n}{BaggingRegressor}\PY{p}{,} \PY{n}{RandomForestClassifier}\PY{p}{,} \PY{n}{GradientBoostingRegressor}\PY{p}{,} \PY{n}{RandomForestRegressor}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{GridSearchCV}\PY{p}{,} \PY{n}{KFold}
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k+kn}{import} \PY{n}{zscore}
\PY{k+kn}{import} \PY{n+nn}{itertools}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k+kn}{import} \PY{n}{StandardScaler}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{cross\PYZus{}decomposition} \PY{k+kn}{import} \PY{n}{PLSRegression}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{cross\PYZus{}val\PYZus{}score}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{tree} \PY{k+kn}{import} \PY{n}{export\PYZus{}text}
\PY{k+kn}{import} \PY{n+nn}{math}
\PY{k+kn}{from} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{colors} \PY{k+kn}{import} \PY{n}{ListedColormap}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{neighbors} \PY{k+kn}{import} \PY{n}{KNeighborsClassifier}

\PY{c+c1}{\PYZsh{} Set working directory}
\PY{n}{directory\PYZus{}path} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/Users/seugley/Desktop/GitHub/Machine\PYZus{}Learning/Stroke\PYZus{}and\PYZus{}Life\PYZus{}Expectancy}\PY{l+s+s1}{\PYZsq{}}
\PY{n}{os}\PY{o}{.}\PY{n}{chdir}\PY{p}{(}\PY{n}{directory\PYZus{}path}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Load the Stroke.csv dataset (Qualitative)}
\PY{n}{stroke} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Stroke.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Use the features of the dataset to build models for predicting whether an individual is at high risk of having a stroke or not}

\PY{c+c1}{\PYZsh{} Load the Life Expectancy.csv dataset (Quantitative)}
\PY{n}{life\PYZus{}expectancy} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Life Expectancy.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Use the features of the dataset to build models for predicting life expectancy}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Qualitative Analysis}

\PY{c+c1}{\PYZsh{} Stroke Data Dictionary}

\PY{c+c1}{\PYZsh{} id: Unique identifier}
\PY{c+c1}{\PYZsh{} gender: Male = 0, Female = 1}
\PY{c+c1}{\PYZsh{} age: Age of the patient}
\PY{c+c1}{\PYZsh{} hypertension: 0 if the patient doesn\PYZsq{}t have hypertension, 1 if the patient has hypertension}
\PY{c+c1}{\PYZsh{} heart\PYZus{}disease: 0 if the patient doesn\PYZsq{}t have any heart diseases, 1 if the patient has a heart disease}
\PY{c+c1}{\PYZsh{} ever\PYZus{}married: Yes = 1 and No = 0}
\PY{c+c1}{\PYZsh{} work\PYZus{}type: Never\PYZus{}worked = 0, Self\PYZhy{}employed = 1, Private = 2, Govt\PYZus{}job = 3, children = 4}
\PY{c+c1}{\PYZsh{} Residence\PYZus{}type: Rural = 0 and Urban = 1}
\PY{c+c1}{\PYZsh{} avg\PYZus{}glucose\PYZus{}level: average glucose level in blood}
\PY{c+c1}{\PYZsh{} bmi: body mass index}
\PY{c+c1}{\PYZsh{} smoking\PYZus{}status: never smoked = 0, smokes = 1, formerly smoked = 2}
\PY{c+c1}{\PYZsh{} stroke: 1 if the patient had a stroke or 0 if not}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Clean Stroke Dataset}

\PY{c+c1}{\PYZsh{} Drop null values}
\PY{n}{stroke\PYZus{}cleaned} \PY{o}{=} \PY{n}{stroke}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Drop \PYZsq{}Unknown\PYZsq{} values in the \PYZsq{}smoking\PYZus{}status\PYZsq{} column}
\PY{n}{stroke\PYZus{}cleaned} \PY{o}{=} \PY{n}{stroke\PYZus{}cleaned}\PY{p}{[}\PY{n}{stroke\PYZus{}cleaned}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{smoking\PYZus{}status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{!=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Unknown}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Drop the \PYZsq{}id\PYZsq{} column}
\PY{n}{stroke\PYZus{}cleaned} \PY{o}{=} \PY{n}{stroke\PYZus{}cleaned}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Count the number of \PYZsq{}Other\PYZsq{} ocurrences in the \PYZsq{}gender\PYZsq{} column}
\PY{n}{other\PYZus{}gender\PYZus{}count} \PY{o}{=} \PY{n}{stroke\PYZus{}cleaned}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gender}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Other}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of }\PY{l+s+s2}{\PYZsq{}}\PY{l+s+s2}{Other}\PY{l+s+s2}{\PYZsq{}}\PY{l+s+s2}{ in gender column: }\PY{l+s+si}{\PYZob{}}\PY{n}{other\PYZus{}gender\PYZus{}count}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Since there is only 1 \PYZsq{}Other\PYZsq{} value in the gender column, I will remove this value to avoid unneccessary encoding}
\PY{n}{stroke\PYZus{}cleaned} \PY{o}{=} \PY{n}{stroke\PYZus{}cleaned}\PY{p}{[}\PY{n}{stroke\PYZus{}cleaned}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gender}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{!=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Other}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Reset index after dropping rows}
\PY{n}{stroke\PYZus{}cleaned} \PY{o}{=} \PY{n}{stroke\PYZus{}cleaned}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{n}{drop}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Number of 'Other' in gender column: 1
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Variable Encoding}

\PY{c+c1}{\PYZsh{} Encoding for the \PYZsq{}gender\PYZsq{} column}
\PY{n}{gender\PYZus{}mapping} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Male}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Female}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{1}\PY{p}{\PYZcb{}}
\PY{n}{stroke\PYZus{}cleaned}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gender}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{stroke\PYZus{}cleaned}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gender}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{n}{gender\PYZus{}mapping}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Encoding for the \PYZsq{}ever\PYZus{}married\PYZsq{} column}
\PY{n}{married\PYZus{}mapping} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Yes}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{No}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{0}\PY{p}{\PYZcb{}}
\PY{n}{stroke\PYZus{}cleaned}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ever\PYZus{}married}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{stroke\PYZus{}cleaned}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ever\PYZus{}married}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{n}{married\PYZus{}mapping}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Encoding for the \PYZsq{}work\PYZus{}type\PYZsq{} column}
\PY{n}{work\PYZus{}mapping} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{children}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{4}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Govt\PYZus{}job}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{3}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Never\PYZus{}worked}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Private}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Self\PYZhy{}employed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{1}\PY{p}{\PYZcb{}}
\PY{n}{stroke\PYZus{}cleaned}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{work\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{stroke\PYZus{}cleaned}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{work\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{n}{work\PYZus{}mapping}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Encoding for the \PYZsq{}Residence\PYZus{}type\PYZsq{} column}
\PY{n}{residence\PYZus{}mapping} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Rural}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Urban}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{1}\PY{p}{\PYZcb{}}
\PY{n}{stroke\PYZus{}cleaned}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Residence\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{stroke\PYZus{}cleaned}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Residence\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{n}{residence\PYZus{}mapping}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Encoding for the \PYZsq{}smoking\PYZus{}status\PYZsq{} column}
\PY{n}{smoking\PYZus{}mapping} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{formerly smoked}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{never smoked}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{smokes}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{1}\PY{p}{\PYZcb{}}
\PY{n}{stroke\PYZus{}cleaned}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{smoking\PYZus{}status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{stroke\PYZus{}cleaned}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{smoking\PYZus{}status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{n}{smoking\PYZus{}mapping}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Rename cleaned dataset to working dataframe for modeling}
\PY{n}{stroke\PYZus{}df} \PY{o}{=} \PY{n}{stroke\PYZus{}cleaned}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Use bootstrapping on dataset to increase observations. Total observations in original dataset = 3425. However, the original cleaned dataset only includes 206 individuals with heart disease, 68 individuals that are a stay\PYZhy{}at\PYZhy{}home parent as a job, 14 individuals who never worked, and 180 individuals who had a stroke. I\PYZsq{}d like to create more data\PYZhy{}points in these variables to make them more robust for modeling}

\PY{k}{def} \PY{n+nf}{bootstrap\PYZus{}category}\PY{p}{(}\PY{n}{df}\PY{p}{,} \PY{n}{column}\PY{p}{,} \PY{n}{category}\PY{p}{,} \PY{n}{target\PYZus{}size}\PY{p}{)}\PY{p}{:}
    \PY{n}{category\PYZus{}data} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{n}{df}\PY{p}{[}\PY{n}{column}\PY{p}{]} \PY{o}{==} \PY{n}{category}\PY{p}{]}
    \PY{n}{replication\PYZus{}factor} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{ceil}\PY{p}{(}\PY{n}{target\PYZus{}size} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{category\PYZus{}data}\PY{p}{)}\PY{p}{)}\PY{p}{)}
    \PY{n}{bootstrapped\PYZus{}data} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{concat}\PY{p}{(}\PY{p}{[}\PY{n}{category\PYZus{}data}\PY{p}{]} \PY{o}{*} \PY{n}{replication\PYZus{}factor}\PY{p}{,} \PY{n}{ignore\PYZus{}index}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    \PY{n}{bootstrapped\PYZus{}data} \PY{o}{=} \PY{n}{bootstrapped\PYZus{}data}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{n}{target\PYZus{}size}\PY{p}{)}
    
    \PY{k}{return} \PY{n}{bootstrapped\PYZus{}data}

\PY{c+c1}{\PYZsh{} Set target sizes for each category}
\PY{n}{target\PYZus{}size\PYZus{}heart\PYZus{}disease} \PY{o}{=} \PY{l+m+mi}{500}  
\PY{n}{target\PYZus{}size\PYZus{}stay\PYZus{}at\PYZus{}home} \PY{o}{=} \PY{l+m+mi}{500}  
\PY{n}{target\PYZus{}size\PYZus{}never\PYZus{}worked} \PY{o}{=} \PY{l+m+mi}{500} 
\PY{n}{target\PYZus{}size\PYZus{}stroke} \PY{o}{=} \PY{l+m+mi}{500} 

\PY{c+c1}{\PYZsh{} Apply bootstrapping to each category}
\PY{n}{bootstrapped\PYZus{}heart\PYZus{}disease} \PY{o}{=} \PY{n}{bootstrap\PYZus{}category}\PY{p}{(}\PY{n}{stroke\PYZus{}df}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{heart\PYZus{}disease}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{target\PYZus{}size\PYZus{}heart\PYZus{}disease}\PY{p}{)}
\PY{n}{bootstrapped\PYZus{}stay\PYZus{}at\PYZus{}home} \PY{o}{=} \PY{n}{bootstrap\PYZus{}category}\PY{p}{(}\PY{n}{stroke\PYZus{}df}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{work\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{n}{target\PYZus{}size\PYZus{}stay\PYZus{}at\PYZus{}home}\PY{p}{)}
\PY{n}{bootstrapped\PYZus{}never\PYZus{}worked} \PY{o}{=} \PY{n}{bootstrap\PYZus{}category}\PY{p}{(}\PY{n}{stroke\PYZus{}df}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{work\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{,} \PY{n}{target\PYZus{}size\PYZus{}never\PYZus{}worked}\PY{p}{)}
\PY{n}{bootstrapped\PYZus{}stroke} \PY{o}{=} \PY{n}{bootstrap\PYZus{}category}\PY{p}{(}\PY{n}{stroke\PYZus{}df}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stroke}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{target\PYZus{}size\PYZus{}stroke}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Concatenate the bootstrapped data with the original cleaned data}
\PY{n}{bootstrapped\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{concat}\PY{p}{(}\PY{p}{[}\PY{n}{stroke\PYZus{}df}\PY{p}{,} \PY{n}{bootstrapped\PYZus{}heart\PYZus{}disease}\PY{p}{,} \PY{n}{bootstrapped\PYZus{}stay\PYZus{}at\PYZus{}home}\PY{p}{,} \PY{n}{bootstrapped\PYZus{}never\PYZus{}worked}\PY{p}{,} \PY{n}{bootstrapped\PYZus{}stroke}\PY{p}{]}\PY{p}{,} \PY{n}{ignore\PYZus{}index}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Shuffle the dataset to mix original and bootstrapped data}
\PY{n}{bootstrapped\PYZus{}df} \PY{o}{=} \PY{n}{bootstrapped\PYZus{}df}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{n}{frac}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{n}{drop}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Rename bootstrapped data to working dataset for modeling}
\PY{n}{stroke\PYZus{}df} \PY{o}{=} \PY{n}{bootstrapped\PYZus{}df}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Stroke Data Summary}

\PY{c+c1}{\PYZsh{} Total number of observations}
\PY{n}{num\PYZus{}observations} \PY{o}{=} \PY{n}{stroke\PYZus{}df}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Total Number of Observations in the Dataset: }\PY{l+s+si}{\PYZob{}}\PY{n}{num\PYZus{}observations}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print the number of males and females in the dataset}
\PY{n}{gender\PYZus{}counts} \PY{o}{=} \PY{n}{stroke\PYZus{}df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gender}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}

\PY{n}{num\PYZus{}males} \PY{o}{=} \PY{n}{gender\PYZus{}counts}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}
\PY{n}{num\PYZus{}females} \PY{o}{=} \PY{n}{gender\PYZus{}counts}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of males in the dataset: }\PY{l+s+si}{\PYZob{}}\PY{n}{num\PYZus{}males}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of females in the dataset: }\PY{l+s+si}{\PYZob{}}\PY{n}{num\PYZus{}females}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print the number of individuals with and without hypertension}
\PY{n}{hypertension\PYZus{}counts} \PY{o}{=} \PY{n}{stroke\PYZus{}df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hypertension}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}

\PY{n}{num\PYZus{}without\PYZus{}hypertension} \PY{o}{=} \PY{n}{hypertension\PYZus{}counts}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}
\PY{n}{num\PYZus{}with\PYZus{}hypertension} \PY{o}{=} \PY{n}{hypertension\PYZus{}counts}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of Individuals With Hypertension: }\PY{l+s+si}{\PYZob{}}\PY{n}{num\PYZus{}with\PYZus{}hypertension}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of Individuals Without Hypertension: }\PY{l+s+si}{\PYZob{}}\PY{n}{num\PYZus{}without\PYZus{}hypertension}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print the number of individuals with and without heart disease}
\PY{n}{heart\PYZus{}disease\PYZus{}counts} \PY{o}{=} \PY{n}{stroke\PYZus{}df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{heart\PYZus{}disease}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}

\PY{n}{num\PYZus{}without\PYZus{}heart\PYZus{}disease} \PY{o}{=} \PY{n}{heart\PYZus{}disease\PYZus{}counts}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}  
\PY{n}{num\PYZus{}with\PYZus{}heart\PYZus{}disease} \PY{o}{=} \PY{n}{heart\PYZus{}disease\PYZus{}counts}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of Individuals With Heart Disease: }\PY{l+s+si}{\PYZob{}}\PY{n}{num\PYZus{}with\PYZus{}heart\PYZus{}disease}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of Individuals Without Heart Disease: }\PY{l+s+si}{\PYZob{}}\PY{n}{num\PYZus{}without\PYZus{}heart\PYZus{}disease}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print the number of individuals who are and are not ever married}
\PY{n}{ever\PYZus{}married\PYZus{}counts} \PY{o}{=} \PY{n}{stroke\PYZus{}df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ever\PYZus{}married}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}

\PY{n}{num\PYZus{}not\PYZus{}ever\PYZus{}married} \PY{o}{=} \PY{n}{ever\PYZus{}married\PYZus{}counts}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}
\PY{n}{num\PYZus{}ever\PYZus{}married} \PY{o}{=} \PY{n}{ever\PYZus{}married\PYZus{}counts}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of Individuals Ever Married: }\PY{l+s+si}{\PYZob{}}\PY{n}{num\PYZus{}ever\PYZus{}married}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of Individuals Not Ever Married: }\PY{l+s+si}{\PYZob{}}\PY{n}{num\PYZus{}not\PYZus{}ever\PYZus{}married}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print the number of individuals in each work type}
\PY{n}{work\PYZus{}type\PYZus{}counts} \PY{o}{=} \PY{n}{stroke\PYZus{}df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{work\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of Individuals in Each Work Type (Never\PYZus{}worked = 0, Self\PYZhy{}employed = 1, Private = 2, Govt\PYZus{}job = 3, children = 4):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{work\PYZus{}type\PYZus{}counts}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print the number of individuals in each residence type}
\PY{n}{residence\PYZus{}type\PYZus{}counts} \PY{o}{=} \PY{n}{stroke\PYZus{}df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Residence\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of Individuals in Each Residence Type (0 = Rural 1 = Urban):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{residence\PYZus{}type\PYZus{}counts}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print the number of individuals in each smoking status category}
\PY{n}{smoking\PYZus{}status\PYZus{}counts} \PY{o}{=} \PY{n}{stroke\PYZus{}df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{smoking\PYZus{}status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of Individuals in Each Smoking Status Category (never smoked = 0, smokes = 1, formerly smoked = 2):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{smoking\PYZus{}status\PYZus{}counts}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print the number of individuals who have and have not had a stroke}
\PY{n}{stroke\PYZus{}counts} \PY{o}{=} \PY{n}{stroke\PYZus{}df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stroke}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}

\PY{n}{num\PYZus{}no\PYZus{}stroke} \PY{o}{=} \PY{n}{stroke\PYZus{}counts}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}
\PY{n}{num\PYZus{}yes\PYZus{}stroke} \PY{o}{=} \PY{n}{stroke\PYZus{}counts}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)} 

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of Individuals Who Have Had a Stroke: }\PY{l+s+si}{\PYZob{}}\PY{n}{num\PYZus{}yes\PYZus{}stroke}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of Individuals Who Have Not Had a Stroke: }\PY{l+s+si}{\PYZob{}}\PY{n}{num\PYZus{}no\PYZus{}stroke}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Numerical summary of the age, avg\PYZus{}glucose\PYZus{}level, and bmi variables}
\PY{n}{selected\PYZus{}columns} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{avg\PYZus{}glucose\PYZus{}level}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bmi}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{stroke\PYZus{}numerical\PYZus{}summary} \PY{o}{=} \PY{n}{stroke\PYZus{}df}\PY{p}{[}\PY{n}{selected\PYZus{}columns}\PY{p}{]}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print the summary}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{stroke\PYZus{}numerical\PYZus{}summary}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Total Number of Observations in the Dataset: 5425
Number of males in the dataset: 2271
Number of females in the dataset: 3154
Number of Individuals With Hypertension: 703
Number of Individuals Without Hypertension: 4722
Number of Individuals With Heart Disease: 807
Number of Individuals Without Heart Disease: 4618
Number of Individuals Ever Married: 3488
Number of Individuals Not Ever Married: 1937
Number of Individuals in Each Work Type (Never\_worked = 0, Self-employed = 1,
Private = 2, Govt\_job = 3, children = 4):
2    2812
1     885
3     646
4     568
0     514
Name: work\_type, dtype: int64
Number of Individuals in Each Residence Type (0 = Rural 1 = Urban):
1    2929
0    2496
Name: Residence\_type, dtype: int64
Number of Individuals in Each Smoking Status Category (never smoked = 0, smokes
= 1, formerly smoked = 2):
0    3175
2    1255
1     995
Name: smoking\_status, dtype: int64
Number of Individuals Who Have Had a Stroke: 788
Number of Individuals Who Have Not Had a Stroke: 4637
               age  avg\_glucose\_level          bmi
count  5425.000000        5425.000000  5425.000000
mean     45.950783         112.148151    29.417954
std      22.954625          50.053917     7.262230
min      10.000000          55.120000    11.500000
25\%      23.000000          78.080000    24.300000
50\%      49.000000          94.040000    28.300000
75\%      66.000000         125.260000    33.100000
max      82.000000         271.740000    92.000000
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{8}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Correlation matrix and heatmap}

\PY{c+c1}{\PYZsh{} Create correlation matrix}
\PY{n}{correlation\PYZus{}matrix} \PY{o}{=} \PY{n}{stroke\PYZus{}df}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{correlation\PYZus{}matrix}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create a heatmap}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
\PY{n}{sns}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{correlation\PYZus{}matrix}\PY{p}{,} \PY{n}{annot}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{coolwarm}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.2f}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linewidths}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
                     gender       age  hypertension  heart\_disease  \textbackslash{}
gender             1.000000 -0.043396     -0.031943      -0.145087
age               -0.043396  1.000000      0.327786       0.414061
hypertension      -0.031943  0.327786      1.000000       0.170318
heart\_disease     -0.145087  0.414061      0.170318       1.000000
ever\_married      -0.023288  0.691312      0.182147       0.214217
work\_type         -0.056405 -0.143185     -0.035936      -0.030171
Residence\_type     0.022589 -0.059843     -0.023737      -0.011127
avg\_glucose\_level -0.093555  0.273409      0.195963       0.238641
bmi               -0.004823  0.203616      0.146646       0.059430
smoking\_status    -0.100098  0.279620      0.068522       0.159247
stroke            -0.021346  0.406154      0.235033       0.187853

                   ever\_married  work\_type  Residence\_type  avg\_glucose\_level  \textbackslash{}
gender                -0.023288  -0.056405        0.022589          -0.093555
age                    0.691312  -0.143185       -0.059843           0.273409
hypertension           0.182147  -0.035936       -0.023737           0.195963
heart\_disease          0.214217  -0.030171       -0.011127           0.238641
ever\_married           1.000000  -0.061015       -0.075800           0.171327
work\_type             -0.061015   1.000000       -0.094787          -0.004901
Residence\_type        -0.075800  -0.094787        1.000000          -0.025851
avg\_glucose\_level      0.171327  -0.004901       -0.025851           1.000000
bmi                    0.265702  -0.126559        0.000153           0.185230
smoking\_status         0.256090   0.049641       -0.012178           0.076596
stroke                 0.212209  -0.037247       -0.015164           0.239070

                        bmi  smoking\_status    stroke
gender            -0.004823       -0.100098 -0.021346
age                0.203616        0.279620  0.406154
hypertension       0.146646        0.068522  0.235033
heart\_disease      0.059430        0.159247  0.187853
ever\_married       0.265702        0.256090  0.212209
work\_type         -0.126559        0.049641 -0.037247
Residence\_type     0.000153       -0.012178 -0.015164
avg\_glucose\_level  0.185230        0.076596  0.239070
bmi                1.000000        0.074657  0.074330
smoking\_status     0.074657        1.000000  0.113181
stroke             0.074330        0.113181  1.000000
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_7_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{9}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Collinearity Evaluation}

\PY{c+c1}{\PYZsh{} Set correlation threshold}
\PY{n}{correlation\PYZus{}threshold} \PY{o}{=} \PY{l+m+mf}{0.65}

\PY{c+c1}{\PYZsh{} Find highly correlated feature pairs}
\PY{n}{highly\PYZus{}correlated\PYZus{}pairs} \PY{o}{=} \PY{p}{[}\PY{p}{]}

\PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{correlation\PYZus{}matrix}\PY{o}{.}\PY{n}{columns}\PY{p}{)}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{correlation\PYZus{}matrix}\PY{o}{.}\PY{n}{columns}\PY{p}{)}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{n+nb}{abs}\PY{p}{(}\PY{n}{correlation\PYZus{}matrix}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{n}{j}\PY{p}{]}\PY{p}{)} \PY{o}{\PYZgt{}} \PY{n}{correlation\PYZus{}threshold}\PY{p}{:}
            \PY{n}{pair} \PY{o}{=} \PY{p}{(}\PY{n}{correlation\PYZus{}matrix}\PY{o}{.}\PY{n}{columns}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{correlation\PYZus{}matrix}\PY{o}{.}\PY{n}{columns}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{p}{,} \PY{n}{correlation\PYZus{}matrix}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{n}{j}\PY{p}{]}\PY{p}{)}
            \PY{n}{highly\PYZus{}correlated\PYZus{}pairs}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{pair}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print highly correlated pairs excluding the target (stroke)}
\PY{n}{target\PYZus{}variable} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stroke}\PY{l+s+s1}{\PYZsq{}}
\PY{k}{for} \PY{n}{pair} \PY{o+ow}{in} \PY{n}{highly\PYZus{}correlated\PYZus{}pairs}\PY{p}{:}
    \PY{k}{if} \PY{n}{target\PYZus{}variable} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{pair}\PY{p}{:}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Highly Correlated Pairs: }\PY{l+s+si}{\PYZob{}}\PY{n}{pair}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} It appears as though age and ever\PYZus{}married are highly correlated, which makes sense as people tend to have been or are married at older ages. This being the only highly correlated pair is a good sign that there aren\PYZsq{}t issues with collinearity}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Highly Correlated Pairs: ('age', 'ever\_married', 0.6913119458910274)
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Logistic Regression Model}

\PY{c+c1}{\PYZsh{} Define features and target variable}
\PY{n}{features} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{avg\PYZus{}glucose\PYZus{}level}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bmi}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{heart\PYZus{}disease}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ever\PYZus{}married}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{work\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Residence\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{smoking\PYZus{}status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{target} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stroke}\PY{l+s+s1}{\PYZsq{}}

\PY{c+c1}{\PYZsh{} Separate features and target variable}
\PY{n}{X} \PY{o}{=} \PY{n}{stroke\PYZus{}df}\PY{p}{[}\PY{n}{features}\PY{p}{]}
\PY{n}{y} \PY{o}{=} \PY{n}{stroke\PYZus{}df}\PY{p}{[}\PY{n}{target}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Split the data into training and testing sets}
\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Fit the logistic regression model}
\PY{n}{logreg\PYZus{}model} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{n}{max\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}
\PY{n}{logreg\PYZus{}model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Predictions on the test set}
\PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{logreg\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Confusion Matrix}
\PY{n}{conf\PYZus{}matrix} \PY{o}{=} \PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}
\PY{n}{conf\PYZus{}matrix\PYZus{}labels} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{conf\PYZus{}matrix}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Actual 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Actual 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{conf\PYZus{}matrix\PYZus{}labels}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Accuracy Score}
\PY{n}{accuracy} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Accuracy Score: }\PY{l+s+si}{\PYZob{}}\PY{n}{accuracy}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Coefficients and p\PYZhy{}values}
\PY{n}{X\PYZus{}train\PYZus{}with\PYZus{}intercept} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{add\PYZus{}constant}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}
\PY{n}{logit\PYZus{}model} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{Logit}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}train\PYZus{}with\PYZus{}intercept}\PY{p}{)}
\PY{n}{result} \PY{o}{=} \PY{n}{logit\PYZus{}model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{result}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} The most significant predictors using this model appear to be age, avg\PYZus{}glucose\PYZus{}level, bmi, and work\PYZus{}type based on their p\PYZhy{}values \PYZlt{} 0.05}

\PY{c+c1}{\PYZsh{} Plot coefficients excluding \PYZsq{}const\PYZsq{}}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
\PY{n}{ci} \PY{o}{=} \PY{n}{result}\PY{o}{.}\PY{n}{conf\PYZus{}int}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{const}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{coef} \PY{o}{=} \PY{n}{result}\PY{o}{.}\PY{n}{params}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{const}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{coef}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{kind}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bar}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{yerr}\PY{o}{=}\PY{p}{(}\PY{n}{ci}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{\PYZhy{}}\PY{n}{ci}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{/}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Logistic Regression Coefficients with Confidence Intervals}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Coefficient Value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Confusion Matrix:
          Predicted 0  Predicted 1
Actual 0          901           33
Actual 1          124           27

Accuracy Score: 0.8552995391705069
Optimization terminated successfully.
         Current function value: 0.308275
         Iterations 8
                           Logit Regression Results
==============================================================================
Dep. Variable:                 stroke   No. Observations:                 4340
Model:                          Logit   Df Residuals:                     4331
Method:                           MLE   Df Model:                            8
Date:                Sat, 17 Aug 2024   Pseudo R-squ.:                  0.2609
Time:                        21:36:20   Log-Likelihood:                -1337.9
converged:                       True   LL-Null:                       -1810.1
Covariance Type:            nonrobust   LLR p-value:                1.516e-198
================================================================================
=====
                        coef    std err          z      P>|z|      [0.025
0.975]
--------------------------------------------------------------------------------
-----
const                -7.8293      0.431    -18.148      0.000      -8.675
-6.984
age                   0.0778      0.004     19.776      0.000       0.070
0.086
avg\_glucose\_level     0.0047      0.001      5.628      0.000       0.003
0.006
bmi                   0.0248      0.008      3.159      0.002       0.009
0.040
heart\_disease        -0.0918      0.113     -0.809      0.419      -0.314
0.131
ever\_married         -0.1196      0.156     -0.764      0.445      -0.426
0.187
work\_type             0.1478      0.075      1.971      0.049       0.001
0.295
Residence\_type       -0.0080      0.098     -0.082      0.935      -0.199
0.183
smoking\_status        0.0900      0.055      1.624      0.104      -0.019
0.199
================================================================================
=====
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_9_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} LDA, QDA, and KNN Models}

\PY{c+c1}{\PYZsh{} Re\PYZhy{}define features including only the significant variables (age, avg\PYZus{}glucose\PYZus{}level, bmi, and work\PYZus{}type)}
\PY{n}{features} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{avg\PYZus{}glucose\PYZus{}level}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bmi}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{work\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{target} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stroke}\PY{l+s+s1}{\PYZsq{}}

\PY{c+c1}{\PYZsh{} Separate features and target variable}
\PY{n}{X} \PY{o}{=} \PY{n}{stroke\PYZus{}df}\PY{p}{[}\PY{n}{features}\PY{p}{]}
\PY{n}{y} \PY{o}{=} \PY{n}{stroke\PYZus{}df}\PY{p}{[}\PY{n}{target}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Split the data into training and testing sets}
\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}


\PY{c+c1}{\PYZsh{} Create function for model evaluation and accuracy score}
\PY{k}{def} \PY{n+nf}{evaluate\PYZus{}model}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{model\PYZus{}name}\PY{p}{)}\PY{p}{:}
   
    \PY{c+c1}{\PYZsh{} Fit the model}
    \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Predictions on the test set}
    \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Confusion Matrix}
    \PY{n}{conf\PYZus{}matrix} \PY{o}{=} \PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}
    \PY{n}{conf\PYZus{}matrix\PYZus{}labels} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{conf\PYZus{}matrix}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Actual 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Actual 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Confusion Matrix for }\PY{l+s+si}{\PYZob{}}\PY{n}{model\PYZus{}name}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{n}{conf\PYZus{}matrix\PYZus{}labels}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Accuracy Score}
    \PY{n}{accuracy} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Accuracy Score for }\PY{l+s+si}{\PYZob{}}\PY{n}{model\PYZus{}name}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{: }\PY{l+s+si}{\PYZob{}}\PY{n}{accuracy}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} LDA}
\PY{n}{lda\PYZus{}model} \PY{o}{=} \PY{n}{LinearDiscriminantAnalysis}\PY{p}{(}\PY{p}{)}
\PY{n}{evaluate\PYZus{}model}\PY{p}{(}\PY{n}{lda\PYZus{}model}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{LDA}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} QDA}
\PY{n}{qda\PYZus{}model} \PY{o}{=} \PY{n}{QuadraticDiscriminantAnalysis}\PY{p}{(}\PY{p}{)}
\PY{n}{evaluate\PYZus{}model}\PY{p}{(}\PY{n}{qda\PYZus{}model}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{QDA}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} KNN (K=1)}
\PY{n}{knn\PYZus{}model} \PY{o}{=} \PY{n}{KNeighborsClassifier}\PY{p}{(}\PY{n}{n\PYZus{}neighbors}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{evaluate\PYZus{}model}\PY{p}{(}\PY{n}{knn\PYZus{}model}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{KNN (K=1)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} KNN (K=10)}
\PY{n}{knn\PYZus{}model} \PY{o}{=} \PY{n}{KNeighborsClassifier}\PY{p}{(}\PY{n}{n\PYZus{}neighbors}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
\PY{n}{evaluate\PYZus{}model}\PY{p}{(}\PY{n}{knn\PYZus{}model}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{KNN (K=10)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} KNN (K=100)}
\PY{n}{knn\PYZus{}model} \PY{o}{=} \PY{n}{KNeighborsClassifier}\PY{p}{(}\PY{n}{n\PYZus{}neighbors}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}
\PY{n}{evaluate\PYZus{}model}\PY{p}{(}\PY{n}{knn\PYZus{}model}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{KNN (K=100)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display plots}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]

Confusion Matrix for LDA:
          Predicted 0  Predicted 1
Actual 0          902           32
Actual 1          118           33

Accuracy Score for LDA: 0.8617511520737328

Confusion Matrix for QDA:
          Predicted 0  Predicted 1
Actual 0          810          124
Actual 1           60           91

Accuracy Score for QDA: 0.8304147465437788

Confusion Matrix for KNN (K=1):
          Predicted 0  Predicted 1
Actual 0          908           26
Actual 1            0          151

Accuracy Score for KNN (K=1): 0.976036866359447

Confusion Matrix for KNN (K=10):
          Predicted 0  Predicted 1
Actual 0          888           46
Actual 1           92           59

Accuracy Score for KNN (K=10): 0.8728110599078341

Confusion Matrix for KNN (K=100):
          Predicted 0  Predicted 1
Actual 0          919           15
Actual 1          141           10

Accuracy Score for KNN (K=100): 0.8562211981566821
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Classification Tree Model}

\PY{c+c1}{\PYZsh{} Initialize tree model}
\PY{n}{tree\PYZus{}model} \PY{o}{=} \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Fit the model}
\PY{n}{tree\PYZus{}model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Predictions on the test set}
\PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{tree\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create confusion matrix}
\PY{n}{conf\PYZus{}matrix} \PY{o}{=} \PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}
\PY{n}{conf\PYZus{}matrix\PYZus{}labels} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{conf\PYZus{}matrix}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Actual 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Actual 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix for Decision Tree (Before CV):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{conf\PYZus{}matrix\PYZus{}labels}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Calculate accuracy score}
\PY{n}{accuracy} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Accuracy Score (Before CV): }\PY{l+s+si}{\PYZob{}}\PY{n}{accuracy}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print the number of nodes in the tree before CV}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Number of nodes in the tree before CV: }\PY{l+s+si}{\PYZob{}}\PY{n}{tree\PYZus{}model}\PY{o}{.}\PY{n}{tree\PYZus{}}\PY{o}{.}\PY{n}{node\PYZus{}count}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot the decision tree}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
\PY{n}{plot\PYZus{}tree}\PY{p}{(}\PY{n}{tree\PYZus{}model}\PY{p}{,} \PY{n}{feature\PYZus{}names}\PY{o}{=}\PY{n}{features}\PY{p}{,} \PY{n}{class\PYZus{}names}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{filled}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{rounded}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Define the parameter grid for grid search using optimal hyperparameters}
\PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{10}\PY{p}{]}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min\PYZus{}samples\PYZus{}split}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min\PYZus{}samples\PYZus{}leaf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
\PY{p}{\PYZcb{}}

\PY{c+c1}{\PYZsh{} Create and perform grid search}
\PY{n}{grid\PYZus{}search} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{tree\PYZus{}model}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{grid\PYZus{}search}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Get the best decision tree from grid search}
\PY{n}{best\PYZus{}tree\PYZus{}model} \PY{o}{=} \PY{n}{grid\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}estimator\PYZus{}}

\PY{c+c1}{\PYZsh{} Print the number of nodes in the best tree after CV}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Number of nodes in the best tree after CV: }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}tree\PYZus{}model}\PY{o}{.}\PY{n}{tree\PYZus{}}\PY{o}{.}\PY{n}{node\PYZus{}count}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot the best decision tree}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
\PY{n}{plot\PYZus{}tree}\PY{p}{(}\PY{n}{best\PYZus{}tree\PYZus{}model}\PY{p}{,} \PY{n}{feature\PYZus{}names}\PY{o}{=}\PY{n}{features}\PY{p}{,} \PY{n}{class\PYZus{}names}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{filled}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{rounded}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Make predictions using the best tree model}
\PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{best\PYZus{}tree\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create confusion matrix}
\PY{n}{conf\PYZus{}matrix} \PY{o}{=} \PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}
\PY{n}{conf\PYZus{}matrix\PYZus{}labels} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{conf\PYZus{}matrix}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Actual 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Actual 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix for Decision Tree (After CV):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{conf\PYZus{}matrix\PYZus{}labels}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Accuracy Score}
\PY{n}{accuracy} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Accuracy Score (After CV): }\PY{l+s+si}{\PYZob{}}\PY{n}{accuracy}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot the decision tree with smaller max depth}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
\PY{n}{plot\PYZus{}tree}\PY{p}{(}\PY{n}{best\PYZus{}tree\PYZus{}model}\PY{p}{,} \PY{n}{feature\PYZus{}names}\PY{o}{=}\PY{n}{features}\PY{p}{,} \PY{n}{class\PYZus{}names}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{filled}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{rounded}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot feature importances}
\PY{n}{feature\PYZus{}importance} \PY{o}{=} \PY{n}{best\PYZus{}tree\PYZus{}model}\PY{o}{.}\PY{n}{feature\PYZus{}importances\PYZus{}}
\PY{n}{feature\PYZus{}importance\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{features}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{feature\PYZus{}importance}\PY{p}{\PYZcb{}}\PY{p}{)}
\PY{n}{feature\PYZus{}importance\PYZus{}df} \PY{o}{=} \PY{n}{feature\PYZus{}importance\PYZus{}df}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
\PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{feature\PYZus{}importance\PYZus{}df}\PY{p}{,} \PY{n}{palette}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{viridis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature Importance Plot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Confusion Matrix for Decision Tree (Before CV):
          Predicted 0  Predicted 1
Actual 0          908           26
Actual 1            0          151

Accuracy Score (Before CV): 0.976036866359447

Number of nodes in the tree before CV: 547
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_11_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]

Number of nodes in the best tree after CV: 367
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_11_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Confusion Matrix for Decision Tree (After CV):
          Predicted 0  Predicted 1
Actual 0          913           21
Actual 1           22          129

Accuracy Score (After CV): 0.96036866359447
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_11_5.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_11_6.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Bagging Model}

\PY{c+c1}{\PYZsh{} Initialize base regressor}
\PY{n}{base\PYZus{}regressor} \PY{o}{=} \PY{n}{DecisionTreeRegressor}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create a bagging regressor with 100 base regressors}
\PY{n}{bagging\PYZus{}model} \PY{o}{=} \PY{n}{BaggingRegressor}\PY{p}{(}\PY{n}{base\PYZus{}regressor}\PY{p}{,} \PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
\PY{n}{bagging\PYZus{}model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Make predictions using the bagging model}
\PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{bagging\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Convert predictions to binary (1 if prediction \PYZgt{} 0.5, else 0)}
\PY{n}{y\PYZus{}pred\PYZus{}binary} \PY{o}{=} \PY{p}{(}\PY{n}{y\PYZus{}pred} \PY{o}{\PYZgt{}} \PY{l+m+mf}{0.5}\PY{p}{)}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{int}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create confusion matrix}
\PY{n}{conf\PYZus{}matrix} \PY{o}{=} \PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred\PYZus{}binary}\PY{p}{)}
\PY{n}{conf\PYZus{}matrix\PYZus{}labels} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{conf\PYZus{}matrix}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Actual 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Actual 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix for Bagging:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{conf\PYZus{}matrix\PYZus{}labels}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Accuracy Score}
\PY{n}{accuracy} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred\PYZus{}binary}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Accuracy Score for Bagging: }\PY{l+s+si}{\PYZob{}}\PY{n}{accuracy}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Extract feature importances}
\PY{n}{feature\PYZus{}importance} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{[}\PY{n}{tree}\PY{o}{.}\PY{n}{feature\PYZus{}importances\PYZus{}} \PY{k}{for} \PY{n}{tree} \PY{o+ow}{in} \PY{n}{bagging\PYZus{}model}\PY{o}{.}\PY{n}{estimators\PYZus{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot feature importance}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
\PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{feature\PYZus{}importance}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{features}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature Importance for Bagging Model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Confusion Matrix for Bagging:
          Predicted 0  Predicted 1
Actual 0          919           15
Actual 1            0          151

Accuracy Score for Bagging: 0.9861751152073732
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_12_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Random Forest Model}

\PY{c+c1}{\PYZsh{} Initialize Random Forest Classifier}
\PY{n}{random\PYZus{}forest\PYZus{}classifier} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Fit Random Forest model}
\PY{n}{random\PYZus{}forest\PYZus{}classifier}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Predict on the test set}
\PY{n}{y\PYZus{}pred\PYZus{}rf} \PY{o}{=} \PY{n}{random\PYZus{}forest\PYZus{}classifier}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create confusion matrix}
\PY{n}{conf\PYZus{}matrix\PYZus{}rf} \PY{o}{=} \PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred\PYZus{}rf}\PY{p}{)}
\PY{n}{conf\PYZus{}matrix\PYZus{}labels\PYZus{}rf} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{conf\PYZus{}matrix\PYZus{}rf}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Actual 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Actual 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix for RandomForest:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{conf\PYZus{}matrix\PYZus{}labels\PYZus{}rf}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Accuracy Score}
\PY{n}{accuracy\PYZus{}rf} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred\PYZus{}rf}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Accuracy Score for Random Forest: }\PY{l+s+si}{\PYZob{}}\PY{n}{accuracy\PYZus{}rf}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Determine variables\PYZsq{} importances}
\PY{n}{feature\PYZus{}importances\PYZus{}rf} \PY{o}{=} \PY{n}{random\PYZus{}forest\PYZus{}classifier}\PY{o}{.}\PY{n}{feature\PYZus{}importances\PYZus{}}
\PY{n}{feature\PYZus{}importance\PYZus{}rf} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{columns}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{feature\PYZus{}importances\PYZus{}rf}\PY{p}{\PYZcb{}}\PY{p}{)}
\PY{n}{feature\PYZus{}importance\PYZus{}rf} \PY{o}{=} \PY{n}{feature\PYZus{}importance\PYZus{}rf}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display the feature importances}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Feature Importance:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{feature\PYZus{}importance\PYZus{}rf}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot feature importances}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
\PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{feature\PYZus{}importance\PYZus{}rf}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature Importance for Random Forest Model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Confusion Matrix for RandomForest:
          Predicted 0  Predicted 1
Actual 0          922           12
Actual 1            0          151

Accuracy Score for Random Forest: 0.9889400921658986

Feature Importance:
             Feature  Importance
1  avg\_glucose\_level    0.342344
0                age    0.327715
2                bmi    0.275027
3          work\_type    0.054914
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_13_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Quantitative Analysis}

\PY{c+c1}{\PYZsh{} Life Expectancy Data Dictionary }

\PY{c+c1}{\PYZsh{} status: Developing or Developed nation (Developing = 0 and Developed = 1)}
\PY{c+c1}{\PYZsh{} adult\PYZus{}mortality: Adult Mortality Rates of both sexes (probability of dying between 15 and 60 years per 1000 population)}
\PY{c+c1}{\PYZsh{} alcohol: Recorded per capita (ages 15+) consumption (in litres) of pure alcohol per year}
\PY{c+c1}{\PYZsh{} percentage\PYZus{}expenditure: Expenditure on health as a percentage of Gross Domestic Product per capita(\PYZpc{})}
\PY{c+c1}{\PYZsh{} hepatitis\PYZus{}b: Hepatitis B (HepB) immunization coverage among 1\PYZhy{}year\PYZhy{}olds (\PYZpc{})}
\PY{c+c1}{\PYZsh{} bmi: Average Body Mass Index of entire country population}
\PY{c+c1}{\PYZsh{} under\PYZus{}five\PYZus{}deaths: Number of under\PYZhy{}five deaths per 1000 population}
\PY{c+c1}{\PYZsh{} polio: Pol3 immunization coverage among 1\PYZhy{}year\PYZhy{}olds (\PYZpc{})}
\PY{c+c1}{\PYZsh{} total\PYZus{}expenditure: General government expenditure on health as a percentage of total government expenditure (\PYZpc{})}
\PY{c+c1}{\PYZsh{} diphtheria: DTP3 immunization coverage among 1\PYZhy{}year\PYZhy{}olds (\PYZpc{})}
\PY{c+c1}{\PYZsh{} hiv\PYZus{}aids: Deaths per 1000 live births HIV/AIDS (0\PYZhy{}4 years)}
\PY{c+c1}{\PYZsh{} country\PYZus{}gdp: Gross Domestic Product per capita (in USD)}
\PY{c+c1}{\PYZsh{} country\PYZus{}population: Population of the country}
\PY{c+c1}{\PYZsh{} thinness\PYZus{}5\PYZus{}to\PYZus{}19\PYZus{}years: Prevalence of thinness among children and adolescents for Age 5 to 19 (\PYZpc{} )}
\PY{c+c1}{\PYZsh{} income\PYZus{}composition\PYZus{}resources: Human Development Index in terms of income composition of resources (index ranging from 0 to 1)}
\PY{c+c1}{\PYZsh{} schooling: Number of years of Schooling}
\PY{c+c1}{\PYZsh{} life\PYZus{}expectancy: Life Expectancy in age}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Clean Life Expectancy Data}

\PY{c+c1}{\PYZsh{} Rename columns}
\PY{n}{column\PYZus{}mapping} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Life expectancy }\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{life\PYZus{}expectancy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Adult Mortality}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adult\PYZus{}mortality}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{infant deaths}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{infant\PYZus{}deaths}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Alcohol}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{alcohol}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{percentage expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{percentage\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Hepatitis B}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hepatitis\PYZus{}b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Measles }\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{measles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ BMI }\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bmi}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{under\PYZhy{}five deaths }\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{under\PYZus{}five\PYZus{}deaths}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Polio}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polio}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Total expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{total\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Diphtheria }\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{diphtheria}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ HIV/AIDS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hiv\PYZus{}aids}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{GDP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{country\PYZus{}gdp}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Population}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{country\PYZus{}population}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ thinness  1\PYZhy{}19 years}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thinness\PYZus{}10\PYZus{}to\PYZus{}19\PYZus{}years}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ thinness 5\PYZhy{}9 years}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thinness\PYZus{}5\PYZus{}to\PYZus{}9\PYZus{}years}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Income composition of resources}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{income\PYZus{}composition\PYZus{}resources}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Schooling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{schooling}\PY{l+s+s1}{\PYZsq{}}
\PY{p}{\PYZcb{}}

\PY{n}{life\PYZus{}expectancy\PYZus{}renamed} \PY{o}{=} \PY{n}{life\PYZus{}expectancy}\PY{o}{.}\PY{n}{rename}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{n}{column\PYZus{}mapping}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Drop \PYZsq{}Country\PYZsq{}, \PYZsq{}Year\PYZsq{}, and infant\PYZus{}deaths columns. Country and year aren\PYZsq{}t necessary for this analysis. Infant deaths and under\PYZhy{}five deaths closely mirror eachother and are highly correlated (0.99 correlation coefficient). I removed infant deaths to avoid possible issues with collinearity later on. I also dropped the \PYZsq{}measles\PYZsq{} column because the dictionary that came with the data says it\PYZsq{}s per 1000 individuals, however, most of the values in this column are \PYZgt{}1000}
\PY{n}{life\PYZus{}expectancy\PYZus{}no\PYZus{}country\PYZus{}year} \PY{o}{=} \PY{n}{life\PYZus{}expectancy\PYZus{}renamed}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Country}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Year}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{infant\PYZus{}deaths}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{measles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Percent expenditure exceeds 100\PYZpc{} in some cases, however, this is sensible in some cases. As \PYZgt{}100\PYZpc{} PE doesn\PYZsq{}t necessarily imply exceeding available income, but rather the proportion of income dedicated to health}

\PY{c+c1}{\PYZsh{} Country GDP was considered to be removed as this is highly correlated with percentage expenditure (0.959), however, keeping country GDP in the models did not have a significant impact on model performance, so, it did not get removed}

\PY{c+c1}{\PYZsh{} The other highly correlated pairs are Income Composition of Resources with Schooling (0.785) and Under\PYZhy{}Five Deaths with Country Population. These were considered for transformation or removal, however, they did not affect the models\PYZsq{} performance significantly. All four of these variables were selected in the Backward Stepwise Selection model and did not perform significantly different than the Forward Selection Model (Forward MSE = 13.568 Backward MSE = 13.465) which did not include any of these four variables}

\PY{c+c1}{\PYZsh{} Map values in the \PYZsq{}status\PYZsq{} column}
\PY{n}{status\PYZus{}mapping} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Developed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Developing}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{0}\PY{p}{\PYZcb{}}
\PY{n}{life\PYZus{}expectancy\PYZus{}mapped} \PY{o}{=} \PY{n}{life\PYZus{}expectancy\PYZus{}no\PYZus{}country\PYZus{}year}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\PY{n}{life\PYZus{}expectancy\PYZus{}mapped}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{life\PYZus{}expectancy\PYZus{}no\PYZus{}country\PYZus{}year}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{status\PYZus{}mapping}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Remove any null values and reset index}
\PY{n}{life\PYZus{}expectancy\PYZus{}no\PYZus{}null} \PY{o}{=} \PY{n}{life\PYZus{}expectancy\PYZus{}mapped}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{p}{)}
\PY{n}{life\PYZus{}expectancy\PYZus{}df} \PY{o}{=} \PY{n}{life\PYZus{}expectancy\PYZus{}no\PYZus{}null}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{n}{drop}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create new column by combining \PYZsq{}thinness\PYZus{}5\PYZus{}to\PYZus{}19\PYZus{}years\PYZsq{} and \PYZsq{}thinness\PYZus{}10\PYZus{}to\PYZus{}19\PYZus{}years\PYZsq{}. These two variables are highly correlated with eachother and made sense to combine them}
\PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thinness\PYZus{}5\PYZus{}to\PYZus{}19\PYZus{}years}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thinness\PYZus{}10\PYZus{}to\PYZus{}19\PYZus{}years}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{+} \PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thinness\PYZus{}5\PYZus{}to\PYZus{}9\PYZus{}years}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Drop individual columns}
\PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thinness\PYZus{}10\PYZus{}to\PYZus{}19\PYZus{}years}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thinness\PYZus{}5\PYZus{}to\PYZus{}9\PYZus{}years}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display the working dataframe for modeling}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
   status  life\_expectancy  adult\_mortality  alcohol  percentage\_expenditure  \textbackslash{}
0       0             65.0            263.0     0.01               71.279624
1       0             59.9            271.0     0.01               73.523582
2       0             59.9            268.0     0.01               73.219243
3       0             59.5            272.0     0.01               78.184215
4       0             59.2            275.0     0.01                7.097109

   hepatitis\_b   bmi  under\_five\_deaths  polio  total\_expenditure  diphtheria  \textbackslash{}
0         65.0  19.1                 83    6.0               8.16        65.0
1         62.0  18.6                 86   58.0               8.18        62.0
2         64.0  18.1                 89   62.0               8.13        64.0
3         67.0  17.6                 93   67.0               8.52        67.0
4         68.0  17.2                 97   68.0               7.87        68.0

   hiv\_aids  country\_gdp  country\_population  income\_composition\_resources  \textbackslash{}
0       0.1   584.259210          33736494.0                         0.479
1       0.1   612.696514            327582.0                         0.476
2       0.1   631.744976          31731688.0                         0.470
3       0.1   669.959000           3696958.0                         0.463
4       0.1    63.537231           2978599.0                         0.454

   schooling  thinness\_5\_to\_19\_years
0       10.1                    34.5
1       10.0                    35.0
2        9.9                    35.4
3        9.8                    35.9
4        9.5                    36.4
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{17}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Life Expectancy Data Summary and Exploration}

\PY{c+c1}{\PYZsh{} Generate numerical summary}
\PY{n}{summary\PYZus{}stats} \PY{o}{=} \PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{summary\PYZus{}stats}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Developed (1) versus Developing (0)}
\PY{n}{status\PYZus{}counts} \PY{o}{=} \PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display counts}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of Developed (1) and Developing (0) Values:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{status\PYZus{}counts}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Generate correlation matrix and heatmap}
\PY{n}{le\PYZus{}correlation\PYZus{}matrix} \PY{o}{=} \PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{n}{le\PYZus{}correlation\PYZus{}matrix}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot heatmap}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{7}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
\PY{n}{sns}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{le\PYZus{}correlation\PYZus{}matrix}\PY{p}{,} \PY{n}{annot}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{coolwarm}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fmt}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{.2f}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{linewidths}\PY{o}{=}\PY{l+m+mf}{.5}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Correlation Heatmap of Life Expectancy Features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Look for highly correlated pairs for possible collinearity}

\PY{c+c1}{\PYZsh{} Correlation threshold}
\PY{n}{le\PYZus{}correlation\PYZus{}threshold} \PY{o}{=} \PY{l+m+mf}{0.65}

\PY{c+c1}{\PYZsh{} Find highly correlated pairs}
\PY{n}{le\PYZus{}highly\PYZus{}correlated\PYZus{}pairs} \PY{o}{=} \PY{p}{[}\PY{p}{]}

\PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{le\PYZus{}correlation\PYZus{}matrix}\PY{o}{.}\PY{n}{columns}\PY{p}{)}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{le\PYZus{}correlation\PYZus{}matrix}\PY{o}{.}\PY{n}{columns}\PY{p}{)}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{n+nb}{abs}\PY{p}{(}\PY{n}{le\PYZus{}correlation\PYZus{}matrix}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{n}{j}\PY{p}{]}\PY{p}{)} \PY{o}{\PYZgt{}} \PY{n}{le\PYZus{}correlation\PYZus{}threshold}\PY{p}{:}
            \PY{n}{pair} \PY{o}{=} \PY{p}{(}\PY{n}{le\PYZus{}correlation\PYZus{}matrix}\PY{o}{.}\PY{n}{columns}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{le\PYZus{}correlation\PYZus{}matrix}\PY{o}{.}\PY{n}{columns}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{p}{,} \PY{n}{le\PYZus{}correlation\PYZus{}matrix}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{n}{j}\PY{p}{]}\PY{p}{)}
            \PY{n}{le\PYZus{}highly\PYZus{}correlated\PYZus{}pairs}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{pair}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print pairs}
\PY{k}{for} \PY{n}{pair} \PY{o+ow}{in} \PY{n}{le\PYZus{}highly\PYZus{}correlated\PYZus{}pairs}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Highly Correlated Pair: }\PY{l+s+si}{\PYZob{}}\PY{n}{pair}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    
\PY{c+c1}{\PYZsh{} Create boxplot matrix of variables}
    
\PY{c+c1}{\PYZsh{} Select variables of interest}
\PY{n}{le\PYZus{}selected\PYZus{}variables} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adult\PYZus{}mortality}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{alcohol}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{percentage\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                       \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hepatitis\PYZus{}b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bmi}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{under\PYZus{}five\PYZus{}deaths}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polio}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                       \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{total\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{diphtheria}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hiv\PYZus{}aids}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{country\PYZus{}gdp}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                       \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{country\PYZus{}population}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thinness\PYZus{}5\PYZus{}to\PYZus{}19\PYZus{}years}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                       \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{income\PYZus{}composition\PYZus{}resources}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{schooling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{life\PYZus{}expectancy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Subset selected variables}
\PY{n}{le\PYZus{}subset\PYZus{}df} \PY{o}{=} \PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{p}{[}\PY{n}{le\PYZus{}selected\PYZus{}variables}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Set number of rows and columns in the matrix}
\PY{n}{num\PYZus{}columns} \PY{o}{=} \PY{l+m+mi}{4}
\PY{n}{num\PYZus{}rows} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{n+nb}{len}\PY{p}{(}\PY{n}{le\PYZus{}selected\PYZus{}variables}\PY{p}{)} \PY{o}{/}\PY{o}{/} \PY{n}{num\PYZus{}columns}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create matrix}
\PY{n}{fig}\PY{p}{,} \PY{n}{axes} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{num\PYZus{}rows}\PY{p}{,} \PY{n}{num\PYZus{}columns}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{)}\PY{p}{)}
\PY{n}{fig}\PY{o}{.}\PY{n}{subplots\PYZus{}adjust}\PY{p}{(}\PY{n}{hspace}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{)} 
\PY{n}{axes} \PY{o}{=} \PY{n}{axes}\PY{o}{.}\PY{n}{flatten}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create boxplots for each variable}
\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{variable} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{le\PYZus{}selected\PYZus{}variables}\PY{p}{)}\PY{p}{:}
    \PY{n}{sns}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{p}{[}\PY{n}{variable}\PY{p}{]}\PY{p}{,} \PY{n}{ax}\PY{o}{=}\PY{n}{axes}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}
    \PY{n}{axes}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{n}{variable}\PY{p}{)}
    
\PY{c+c1}{\PYZsh{} Hide empty plots}
\PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{le\PYZus{}selected\PYZus{}variables}\PY{p}{)}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{axes}\PY{p}{)}\PY{p}{)}\PY{p}{:}
    \PY{n}{axes}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    
\PY{c+c1}{\PYZsh{} Display boxplot matrix}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create histogram matrix of variables}

\PY{c+c1}{\PYZsh{} Set the number of rows and columns in the matrix}
\PY{n}{num\PYZus{}columns} \PY{o}{=} \PY{l+m+mi}{4}
\PY{n}{num\PYZus{}rows} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{n+nb}{len}\PY{p}{(}\PY{n}{le\PYZus{}selected\PYZus{}variables}\PY{p}{)} \PY{o}{/}\PY{o}{/} \PY{n}{num\PYZus{}columns}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create a matrix of subplots for histograms}
\PY{n}{fig}\PY{p}{,} \PY{n}{axes} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{num\PYZus{}rows}\PY{p}{,} \PY{n}{num\PYZus{}columns}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{)}\PY{p}{)}
\PY{n}{fig}\PY{o}{.}\PY{n}{subplots\PYZus{}adjust}\PY{p}{(}\PY{n}{hspace}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{)}
\PY{n}{axes} \PY{o}{=} \PY{n}{axes}\PY{o}{.}\PY{n}{flatten}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create histograms for each variable}
\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{variable} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{le\PYZus{}selected\PYZus{}variables}\PY{p}{)}\PY{p}{:}
    \PY{n}{sns}\PY{o}{.}\PY{n}{histplot}\PY{p}{(}\PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{p}{[}\PY{n}{variable}\PY{p}{]}\PY{p}{,} \PY{n}{kde}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{ax}\PY{o}{=}\PY{n}{axes}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}
    \PY{n}{axes}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{n}{variable}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Hide empty plots}
\PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{le\PYZus{}selected\PYZus{}variables}\PY{p}{)}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{axes}\PY{p}{)}\PY{p}{)}\PY{p}{:}
    \PY{n}{axes}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display histogram matrix}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create function that creates scatterplot matrix with best\PYZhy{}fit line for all variables vs life expectancy}
\PY{k}{def} \PY{n+nf}{scatterplot\PYZus{}matrix\PYZus{}with\PYZus{}fit}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{variables}\PY{p}{,} \PY{n}{target\PYZus{}variable}\PY{p}{,} \PY{n}{num\PYZus{}columns}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,} \PY{l+m+mi}{12}\PY{p}{)}\PY{p}{,} \PY{n}{hspace}\PY{o}{=}\PY{l+m+mf}{0.6}\PY{p}{,} \PY{n}{wspace}\PY{o}{=}\PY{l+m+mf}{0.4}\PY{p}{)}\PY{p}{:}
    \PY{n}{num\PYZus{}plots} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{variables}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}
    \PY{n}{num\PYZus{}rows} \PY{o}{=} \PY{n}{math}\PY{o}{.}\PY{n}{ceil}\PY{p}{(}\PY{n}{num\PYZus{}plots} \PY{o}{/} \PY{n}{num\PYZus{}columns}\PY{p}{)}
    
    \PY{n}{fig}\PY{p}{,} \PY{n}{axes} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{num\PYZus{}rows}\PY{p}{,} \PY{n}{num\PYZus{}columns}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{n}{figsize}\PY{p}{)}
    \PY{n}{fig}\PY{o}{.}\PY{n}{subplots\PYZus{}adjust}\PY{p}{(}\PY{n}{hspace}\PY{o}{=}\PY{n}{hspace}\PY{p}{,} \PY{n}{wspace}\PY{o}{=}\PY{n}{wspace}\PY{p}{)} 
    
    \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{variable} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{variables}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{n}{variable} \PY{o}{!=} \PY{n}{target\PYZus{}variable}\PY{p}{:}
            \PY{n}{row} \PY{o}{=} \PY{n}{i} \PY{o}{/}\PY{o}{/} \PY{n}{num\PYZus{}columns}
            \PY{n}{col} \PY{o}{=} \PY{n}{i} \PY{o}{\PYZpc{}} \PY{n}{num\PYZus{}columns}
            \PY{n}{ax} \PY{o}{=} \PY{n}{axes}\PY{p}{[}\PY{n}{row}\PY{p}{,} \PY{n}{col}\PY{p}{]}
            
            \PY{c+c1}{\PYZsh{} Scatterplot}
            \PY{n}{sns}\PY{o}{.}\PY{n}{scatterplot}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{data}\PY{p}{,} \PY{n}{x}\PY{o}{=}\PY{n}{variable}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{target\PYZus{}variable}\PY{p}{,} \PY{n}{ax}\PY{o}{=}\PY{n}{ax}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Fit linear regression line}
            \PY{n}{sns}\PY{o}{.}\PY{n}{regplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{variable}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{target\PYZus{}variable}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{data}\PY{p}{,} \PY{n}{ax}\PY{o}{=}\PY{n}{ax}\PY{p}{,} \PY{n}{line\PYZus{}kws}\PY{o}{=}\PY{p}{\PYZob{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{color}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{red}\PY{l+s+s2}{\PYZdq{}}\PY{p}{\PYZcb{}}\PY{p}{)}
            
            \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{variable}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{ vs }\PY{l+s+si}{\PYZob{}}\PY{n}{target\PYZus{}variable}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{n}{variable}\PY{p}{)}
            \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{n}{target\PYZus{}variable}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} Remove empty subplots}
    \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}plots}\PY{p}{,} \PY{n}{num\PYZus{}rows} \PY{o}{*} \PY{n}{num\PYZus{}columns}\PY{p}{)}\PY{p}{:}
        \PY{n}{fig}\PY{o}{.}\PY{n}{delaxes}\PY{p}{(}\PY{n}{axes}\PY{o}{.}\PY{n}{flatten}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}
    
    \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Use function to create the scatterplot matrix}
\PY{n}{scatterplot\PYZus{}matrix\PYZus{}with\PYZus{}fit}\PY{p}{(}\PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{p}{,} \PY{n}{le\PYZus{}selected\PYZus{}variables}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{life\PYZus{}expectancy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{hspace}\PY{o}{=}\PY{l+m+mf}{0.8}\PY{p}{,} \PY{n}{wspace}\PY{o}{=}\PY{l+m+mf}{0.4}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
            status  life\_expectancy  adult\_mortality      alcohol  \textbackslash{}
count  1649.000000      1649.000000      1649.000000  1649.000000
mean      0.146756        69.302304       168.215282     4.533196
std       0.353969         8.796834       125.310417     4.029189
min       0.000000        44.000000         1.000000     0.010000
25\%       0.000000        64.400000        77.000000     0.810000
50\%       0.000000        71.700000       148.000000     3.790000
75\%       0.000000        75.000000       227.000000     7.340000
max       1.000000        89.000000       723.000000    17.870000

       percentage\_expenditure  hepatitis\_b          bmi  under\_five\_deaths  \textbackslash{}
count             1649.000000  1649.000000  1649.000000        1649.000000
mean               698.973558    79.217708    38.128623          44.220133
std               1759.229336    25.604664    19.754249         162.897999
min                  0.000000     2.000000     2.000000           0.000000
25\%                 37.438577    74.000000    19.500000           1.000000
50\%                145.102253    89.000000    43.700000           4.000000
75\%                509.389994    96.000000    55.800000          29.000000
max              18961.348600    99.000000    77.100000        2100.000000

             polio  total\_expenditure   diphtheria     hiv\_aids  \textbackslash{}
count  1649.000000        1649.000000  1649.000000  1649.000000
mean     83.564585           5.955925    84.155246     1.983869
std      22.450557           2.299385    21.579193     6.032360
min       3.000000           0.740000     2.000000     0.100000
25\%      81.000000           4.410000    82.000000     0.100000
50\%      93.000000           5.840000    92.000000     0.100000
75\%      97.000000           7.470000    97.000000     0.700000
max      99.000000          14.390000    99.000000    50.600000

         country\_gdp  country\_population  income\_composition\_resources  \textbackslash{}
count    1649.000000        1.649000e+03                   1649.000000
mean     5566.031887        1.465363e+07                      0.631551
std     11475.900117        7.046039e+07                      0.183089
min         1.681350        3.400000e+01                      0.000000
25\%       462.149650        1.918970e+05                      0.509000
50\%      1592.572182        1.419631e+06                      0.673000
75\%      4718.512910        7.658972e+06                      0.751000
max    119172.741800        1.293859e+09                      0.936000

         schooling  thinness\_5\_to\_19\_years
count  1649.000000             1649.000000
mean     12.119891                9.758399
std       2.795388                9.084707
min       4.200000                0.200000
25\%      10.300000                3.300000
50\%      12.300000                6.500000
75\%      14.000000               14.000000
max      20.700000               55.400000
Number of Developed (1) and Developing (0) Values:
0    1407
1     242
Name: status, dtype: int64
                                status  life\_expectancy  adult\_mortality  \textbackslash{}
status                        1.000000         0.442798        -0.278173
life\_expectancy               0.442798         1.000000        -0.702523
adult\_mortality              -0.278173        -0.702523         1.000000
alcohol                       0.607782         0.402718        -0.175535
percentage\_expenditure        0.461688         0.409631        -0.237610
hepatitis\_b                   0.140351         0.199935        -0.105225
bmi                           0.298380         0.542042        -0.351542
under\_five\_deaths            -0.109847        -0.192265         0.060365
polio                         0.201917         0.327294        -0.199853
total\_expenditure             0.192538         0.174718        -0.085227
diphtheria                    0.201654         0.341331        -0.191429
hiv\_aids                     -0.129555        -0.592236         0.550691
country\_gdp                   0.484801         0.441322        -0.255035
country\_population           -0.034790        -0.022305        -0.015012
income\_composition\_resources  0.463615         0.721083        -0.442203
schooling                     0.512543         0.727630        -0.421171
thinness\_5\_to\_19\_years       -0.313338        -0.466150         0.284697

                               alcohol  percentage\_expenditure  hepatitis\_b  \textbackslash{}
status                        0.607782                0.461688     0.140351
life\_expectancy               0.402718                0.409631     0.199935
adult\_mortality              -0.175535               -0.237610    -0.105225
alcohol                       1.000000                0.417047     0.109889
percentage\_expenditure        0.417047                1.000000     0.016760
hepatitis\_b                   0.109889                0.016760     1.000000
bmi                           0.353396                0.242738     0.143302
under\_five\_deaths            -0.101082               -0.092158    -0.240766
polio                         0.240315                0.128626     0.463331
total\_expenditure             0.214885                0.183872     0.113327
diphtheria                    0.242951                0.134813     0.588990
hiv\_aids                     -0.027113               -0.095085    -0.094802
country\_gdp                   0.443433                0.959299     0.041850
country\_population           -0.028880               -0.016792    -0.129723
income\_composition\_resources  0.561074                0.402170     0.184921
schooling                     0.616975                0.422088     0.215182
thinness\_5\_to\_19\_years       -0.402245               -0.260066    -0.133773

                                   bmi  under\_five\_deaths     polio  \textbackslash{}
status                        0.298380          -0.109847  0.201917
life\_expectancy               0.542042          -0.192265  0.327294
adult\_mortality              -0.351542           0.060365 -0.199853
alcohol                       0.353396          -0.101082  0.240315
percentage\_expenditure        0.242738          -0.092158  0.128626
hepatitis\_b                   0.143302          -0.240766  0.463331
bmi                           1.000000          -0.242137  0.186268
under\_five\_deaths            -0.242137           1.000000 -0.171164
polio                         0.186268          -0.171164  1.000000
total\_expenditure             0.189469          -0.145803  0.119768
diphtheria                    0.176295          -0.178448  0.609245
hiv\_aids                     -0.210897           0.019476 -0.107885
country\_gdp                   0.266114          -0.100331  0.156809
country\_population           -0.081416           0.658680 -0.045387
income\_composition\_resources  0.510505          -0.148097  0.314682
schooling                     0.554844          -0.226013  0.350147
thinness\_5\_to\_19\_years       -0.560775           0.472116 -0.172446

                              total\_expenditure  diphtheria  hiv\_aids  \textbackslash{}
status                                 0.192538    0.201654 -0.129555
life\_expectancy                        0.174718    0.341331 -0.592236
adult\_mortality                       -0.085227   -0.191429  0.550691
alcohol                                0.214885    0.242951 -0.027113
percentage\_expenditure                 0.183872    0.134813 -0.095085
hepatitis\_b                            0.113327    0.588990 -0.094802
bmi                                    0.189469    0.176295 -0.210897
under\_five\_deaths                     -0.145803   -0.178448  0.019476
polio                                  0.119768    0.609245 -0.107885
total\_expenditure                      1.000000    0.129915  0.043101
diphtheria                             0.129915    1.000000 -0.117601
hiv\_aids                               0.043101   -0.117601  1.000000
country\_gdp                            0.180373    0.158438 -0.108081
country\_population                    -0.079962   -0.039898 -0.027801
income\_composition\_resources           0.183653    0.343262 -0.248590
schooling                              0.243783    0.350398 -0.211840
thinness\_5\_to\_19\_years                -0.217854   -0.187488  0.181196

                              country\_gdp  country\_population  \textbackslash{}
status                           0.484801           -0.034790
life\_expectancy                  0.441322           -0.022305
adult\_mortality                 -0.255035           -0.015012
alcohol                          0.443433           -0.028880
percentage\_expenditure           0.959299           -0.016792
hepatitis\_b                      0.041850           -0.129723
bmi                              0.266114           -0.081416
under\_five\_deaths               -0.100331            0.658680
polio                            0.156809           -0.045387
total\_expenditure                0.180373           -0.079962
diphtheria                       0.158438           -0.039898
hiv\_aids                        -0.108081           -0.027801
country\_gdp                      1.000000           -0.020369
country\_population              -0.020369            1.000000
income\_composition\_resources     0.446856           -0.008132
schooling                        0.467947           -0.040312
thinness\_5\_to\_19\_years          -0.282874            0.285398

                              income\_composition\_resources  schooling  \textbackslash{}
status                                            0.463615   0.512543
life\_expectancy                                   0.721083   0.727630
adult\_mortality                                  -0.442203  -0.421171
alcohol                                           0.561074   0.616975
percentage\_expenditure                            0.402170   0.422088
hepatitis\_b                                       0.184921   0.215182
bmi                                               0.510505   0.554844
under\_five\_deaths                                -0.148097  -0.226013
polio                                             0.314682   0.350147
total\_expenditure                                 0.183653   0.243783
diphtheria                                        0.343262   0.350398
hiv\_aids                                         -0.248590  -0.211840
country\_gdp                                       0.446856   0.467947
country\_population                               -0.008132  -0.040312
income\_composition\_resources                      1.000000   0.784741
schooling                                         0.784741   1.000000
thinness\_5\_to\_19\_years                           -0.454299  -0.490710

                              thinness\_5\_to\_19\_years
status                                     -0.313338
life\_expectancy                            -0.466150
adult\_mortality                             0.284697
alcohol                                    -0.402245
percentage\_expenditure                     -0.260066
hepatitis\_b                                -0.133773
bmi                                        -0.560775
under\_five\_deaths                           0.472116
polio                                      -0.172446
total\_expenditure                          -0.217854
diphtheria                                 -0.187488
hiv\_aids                                    0.181196
country\_gdp                                -0.282874
country\_population                          0.285398
income\_composition\_resources               -0.454299
schooling                                  -0.490710
thinness\_5\_to\_19\_years                      1.000000
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_16_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Highly Correlated Pair: ('life\_expectancy', 'adult\_mortality',
-0.7025230623069735)
Highly Correlated Pair: ('life\_expectancy', 'income\_composition\_resources',
0.7210825929172864)
Highly Correlated Pair: ('life\_expectancy', 'schooling', 0.7276300323211043)
Highly Correlated Pair: ('percentage\_expenditure', 'country\_gdp',
0.9592988569672184)
Highly Correlated Pair: ('under\_five\_deaths', 'country\_population',
0.6586796907106565)
Highly Correlated Pair: ('income\_composition\_resources', 'schooling',
0.7847405811682984)
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_16_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_16_4.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_16_5.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{18}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Select Predictors, Define X and y, Split into test and train sets, Normalize Data}

\PY{c+c1}{\PYZsh{} Select predictors}
\PY{n}{predictors} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adult\PYZus{}mortality}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{alcohol}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{percentage\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hepatitis\PYZus{}b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bmi}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{under\PYZus{}five\PYZus{}deaths}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polio}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{country\PYZus{}gdp}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{total\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{diphtheria}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hiv\PYZus{}aids}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{country\PYZus{}population}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thinness\PYZus{}5\PYZus{}to\PYZus{}19\PYZus{}years}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{schooling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{income\PYZus{}composition\PYZus{}resources}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Define X and y}
\PY{n}{X} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{add\PYZus{}constant}\PY{p}{(}\PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{p}{[}\PY{n}{predictors}\PY{p}{]}\PY{p}{)}
\PY{n}{y} \PY{o}{=} \PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{life\PYZus{}expectancy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Split data into training and testing sets}
\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Data Normalization (on both test and train sets)}

\PY{c+c1}{\PYZsh{} Convert percentage variables to decimals}
\PY{n}{percentage\PYZus{}columns} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hepatitis\PYZus{}b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polio}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{total\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{diphtheria}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thinness\PYZus{}5\PYZus{}to\PYZus{}19\PYZus{}years}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{percentage\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{X\PYZus{}train}\PY{p}{[}\PY{n}{percentage\PYZus{}columns}\PY{p}{]} \PY{o}{/}\PY{o}{=} \PY{l+m+mi}{100}
\PY{n}{X\PYZus{}test}\PY{p}{[}\PY{n}{percentage\PYZus{}columns}\PY{p}{]} \PY{o}{/}\PY{o}{=} \PY{l+m+mi}{100}

\PY{c+c1}{\PYZsh{} Define X and y}
\PY{n}{X\PYZus{}train} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{add\PYZus{}constant}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{[}\PY{n}{predictors}\PY{p}{]}\PY{p}{)}
\PY{n}{X\PYZus{}test} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{add\PYZus{}constant}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{[}\PY{n}{predictors}\PY{p}{]}\PY{p}{)}
\PY{n}{y\PYZus{}train} \PY{o}{=} \PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{index}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{life\PYZus{}expectancy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{index}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{life\PYZus{}expectancy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{19}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Linear Regression Model}

\PY{c+c1}{\PYZsh{} Initialize linear regression model}
\PY{n}{linear\PYZus{}model} \PY{o}{=} \PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Fit model}
\PY{n}{linear\PYZus{}model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Make predictions on test set}
\PY{n}{linear\PYZus{}pred} \PY{o}{=} \PY{n}{linear\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Evaluate model with MSE}
\PY{n}{linear\PYZus{}mse} \PY{o}{=} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{linear\PYZus{}pred}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Test Error (MSE) for Linear Regression: }\PY{l+s+si}{\PYZob{}}\PY{n}{linear\PYZus{}mse}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Summary of Linear Regression Model}
\PY{n}{X\PYZus{}with\PYZus{}intercept} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{add\PYZus{}constant}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}
\PY{n}{sm\PYZus{}model} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{OLS}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}with\PYZus{}intercept}\PY{p}{)}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{n}{sm\PYZus{}model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot coefficients with confidence intervals}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
\PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{sm\PYZus{}model}\PY{o}{.}\PY{n}{params}\PY{o}{.}\PY{n}{index}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{sm\PYZus{}model}\PY{o}{.}\PY{n}{params}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{skyblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{errorbar}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{sm\PYZus{}model}\PY{o}{.}\PY{n}{params}\PY{o}{.}\PY{n}{index}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{sm\PYZus{}model}\PY{o}{.}\PY{n}{params}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{,} \PY{n}{yerr}\PY{o}{=}\PY{n}{sm\PYZus{}model}\PY{o}{.}\PY{n}{conf\PYZus{}int}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{n}{sm\PYZus{}model}\PY{o}{.}\PY{n}{params}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{,} \PY{n}{fmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{none}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{black}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{capsize}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Linear Regression Coefficients with Confidence Intervals}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Coefficients}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Coefficient Values}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{45}\PY{p}{,} \PY{n}{ha}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{right}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Test Error (MSE) for Linear Regression: 13.912785384724556
                            OLS Regression Results
==============================================================================
Dep. Variable:        life\_expectancy   R-squared:                       0.832
Model:                            OLS   Adj. R-squared:                  0.830
Method:                 Least Squares   F-statistic:                     402.2
Date:                Sat, 17 Aug 2024   Prob (F-statistic):               0.00
Time:                        21:37:03   Log-Likelihood:                -3576.2
No. Observations:                1319   AIC:                             7186.
Df Residuals:                    1302   BIC:                             7274.
Df Model:                          16
Covariance Type:            nonrobust
================================================================================
================
                                   coef    std err          t      P>|t|
[0.025      0.975]
--------------------------------------------------------------------------------
----------------
const                           52.4693      0.834     62.934      0.000
50.834      54.105
status                           1.0152      0.393      2.584      0.010
0.244       1.786
adult\_mortality                 -0.0175      0.001    -16.563      0.000
-0.020      -0.015
alcohol                         -0.1692      0.037     -4.608      0.000
-0.241      -0.097
percentage\_expenditure           0.0398      0.021      1.858      0.063
-0.002       0.082
hepatitis\_b                     -1.0117      0.495     -2.042      0.041
-1.983      -0.040
bmi                              0.0291      0.007      4.290      0.000
0.016       0.042
under\_five\_deaths               -0.0021      0.001     -2.204      0.028
-0.004      -0.000
polio                            1.0984      0.575      1.911      0.056
-0.029       2.226
country\_gdp                  -3.066e-06   3.38e-05     -0.091      0.928
-6.93e-05    6.32e-05
total\_expenditure                7.7530      4.591      1.689      0.091
-1.253      16.759
diphtheria                       2.1556      0.678      3.177      0.002
0.825       3.487
hiv\_aids                        -0.4332      0.020    -21.891      0.000
-0.472      -0.394
country\_population            2.494e-09   2.17e-09      1.149      0.251
-1.77e-09    6.75e-09
thinness\_5\_to\_19\_years          -3.6151      1.567     -2.306      0.021
-6.690      -0.540
schooling                        0.9795      0.067     14.585      0.000
0.848       1.111
income\_composition\_resources     9.4645      0.892     10.605      0.000
7.714      11.215
==============================================================================
Omnibus:                       29.236   Durbin-Watson:                   2.053
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               43.742
Skew:                          -0.215   Prob(JB):                     3.17e-10
Kurtosis:                       3.782   Cond. No.                     2.89e+09
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly
specified.
[2] The condition number is large, 2.89e+09. This might indicate that there are
strong multicollinearity or other numerical problems.
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_18_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{20}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Best Subset Selection Model}

\PY{c+c1}{\PYZsh{} I adjusted the predictors by removing country\PYZus{}gdp and country\PYZus{}population, as those features had really high p\PYZhy{}values in the linear regression summary and limited computing power capability}
\PY{n}{best\PYZus{}subset\PYZus{}predictors} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adult\PYZus{}mortality}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{alcohol}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{percentage\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hepatitis\PYZus{}b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bmi}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{under\PYZus{}five\PYZus{}deaths}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polio}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{total\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{diphtheria}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hiv\PYZus{}aids}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thinness\PYZus{}5\PYZus{}to\PYZus{}19\PYZus{}years}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{schooling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{income\PYZus{}composition\PYZus{}resources}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{n}{best\PYZus{}model} \PY{o}{=} \PY{k+kc}{None}
\PY{n}{best\PYZus{}mse} \PY{o}{=} \PY{n+nb}{float}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{inf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{k}{for} \PY{n}{L} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{best\PYZus{}subset\PYZus{}predictors}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{subset} \PY{o+ow}{in} \PY{n}{itertools}\PY{o}{.}\PY{n}{combinations}\PY{p}{(}\PY{n}{best\PYZus{}subset\PYZus{}predictors}\PY{p}{,} \PY{n}{L}\PY{p}{)}\PY{p}{:}
        \PY{n}{subset\PYZus{}X\PYZus{}train} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{p}{[}\PY{n+nb}{list}\PY{p}{(}\PY{n}{subset}\PY{p}{)}\PY{p}{]}
        \PY{n}{subset\PYZus{}X\PYZus{}test} \PY{o}{=} \PY{n}{X\PYZus{}test}\PY{p}{[}\PY{n+nb}{list}\PY{p}{(}\PY{n}{subset}\PY{p}{)}\PY{p}{]}

        \PY{n}{model} \PY{o}{=} \PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}
        \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{subset\PYZus{}X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
        \PY{n}{predictions} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{subset\PYZus{}X\PYZus{}test}\PY{p}{)}
        \PY{n}{mse} \PY{o}{=} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{predictions}\PY{p}{)}

        \PY{k}{if} \PY{n}{mse} \PY{o}{\PYZlt{}} \PY{n}{best\PYZus{}mse}\PY{p}{:}
            \PY{n}{best\PYZus{}mse} \PY{o}{=} \PY{n}{mse}
            \PY{n}{best\PYZus{}model} \PY{o}{=} \PY{n}{model}
            \PY{n}{best\PYZus{}subset} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n}{subset}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Subset: }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}subset}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Test Error (MSE) for Best Subset: }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}mse}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Slight improvement in MSE with Best Subset Model}

\PY{c+c1}{\PYZsh{} Get the coefficients and corresponding predictors}
\PY{n}{coefficients} \PY{o}{=} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{coef\PYZus{}}
\PY{n}{predictors} \PY{o}{=} \PY{n}{best\PYZus{}subset}

\PY{c+c1}{\PYZsh{} Create a df}
\PY{n}{coefficients\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predictor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{predictors}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Coefficient}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{coefficients}\PY{p}{\PYZcb{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot coefficients}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
\PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Coefficient}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predictor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{coefficients\PYZus{}df}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{skyblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Linear Regression Coefficients for Best Subset}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Coefficient Value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predictor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Best Subset: ['adult\_mortality', 'percentage\_expenditure', 'bmi',
'under\_five\_deaths', 'polio', 'diphtheria', 'hiv\_aids', 'schooling',
'income\_composition\_resources']
Test Error (MSE) for Best Subset: 13.610841001767238
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_19_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{21}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Forward Stepwise Selection}

\PY{k}{def} \PY{n+nf}{forward\PYZus{}stepwise\PYZus{}selection}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{predictors}\PY{p}{)}\PY{p}{:}
    \PY{n}{selected\PYZus{}predictors} \PY{o}{=} \PY{p}{[}\PY{p}{]}
    \PY{n}{best\PYZus{}mse} \PY{o}{=} \PY{n+nb}{float}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{inf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    
    \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{predictors}\PY{p}{)}\PY{p}{)}\PY{p}{:}
        \PY{n}{remaining\PYZus{}predictors} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{n}{predictors}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n+nb}{set}\PY{p}{(}\PY{n}{selected\PYZus{}predictors}\PY{p}{)}\PY{p}{)}
        \PY{n}{best\PYZus{}subset} \PY{o}{=} \PY{k+kc}{None}
        
        \PY{k}{for} \PY{n}{predictor} \PY{o+ow}{in} \PY{n}{remaining\PYZus{}predictors}\PY{p}{:}
            \PY{n}{subset} \PY{o}{=} \PY{n}{selected\PYZus{}predictors} \PY{o}{+} \PY{p}{[}\PY{n}{predictor}\PY{p}{]}
            \PY{n}{subset\PYZus{}X\PYZus{}train} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{p}{[}\PY{n}{subset}\PY{p}{]}
            \PY{n}{subset\PYZus{}X\PYZus{}test} \PY{o}{=} \PY{n}{X\PYZus{}test}\PY{p}{[}\PY{n}{subset}\PY{p}{]}

            \PY{n}{model} \PY{o}{=} \PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{subset\PYZus{}X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
            \PY{n}{predictions} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{subset\PYZus{}X\PYZus{}test}\PY{p}{)}
            \PY{n}{mse} \PY{o}{=} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{predictions}\PY{p}{)}

            \PY{k}{if} \PY{n}{mse} \PY{o}{\PYZlt{}} \PY{n}{best\PYZus{}mse}\PY{p}{:}
                \PY{n}{best\PYZus{}mse} \PY{o}{=} \PY{n}{mse}
                \PY{n}{best\PYZus{}subset} \PY{o}{=} \PY{n}{subset}
        
        \PY{k}{if} \PY{n}{best\PYZus{}subset}\PY{p}{:}
            \PY{n}{selected\PYZus{}predictors} \PY{o}{=} \PY{n}{best\PYZus{}subset}
    
    \PY{k}{return} \PY{n}{selected\PYZus{}predictors}\PY{p}{,} \PY{n}{best\PYZus{}mse}

\PY{n}{forward\PYZus{}selected\PYZus{}predictors}\PY{p}{,} \PY{n}{forward\PYZus{}best\PYZus{}mse} \PY{o}{=} \PY{n}{forward\PYZus{}stepwise\PYZus{}selection}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{predictors}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Forward Stepwise Selection Predictors: }\PY{l+s+si}{\PYZob{}}\PY{n}{forward\PYZus{}selected\PYZus{}predictors}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Test Error (MSE) for Forward Stepwise Selection: }\PY{l+s+si}{\PYZob{}}\PY{n}{forward\PYZus{}best\PYZus{}mse}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Backward Stepwise Selection}

\PY{k}{def} \PY{n+nf}{backward\PYZus{}stepwise\PYZus{}selection}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{predictors}\PY{p}{)}\PY{p}{:}
    \PY{n}{selected\PYZus{}predictors} \PY{o}{=} \PY{n}{predictors}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
    \PY{n}{best\PYZus{}mse} \PY{o}{=} \PY{n+nb}{float}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{inf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    
    \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{predictors}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
        \PY{n}{best\PYZus{}subset} \PY{o}{=} \PY{k+kc}{None}
        
        \PY{k}{for} \PY{n}{predictor} \PY{o+ow}{in} \PY{n}{selected\PYZus{}predictors}\PY{p}{:}
            \PY{n}{remaining\PYZus{}predictors} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{n}{selected\PYZus{}predictors}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n+nb}{set}\PY{p}{(}\PY{p}{[}\PY{n}{predictor}\PY{p}{]}\PY{p}{)}\PY{p}{)}
            \PY{n}{subset\PYZus{}X\PYZus{}train} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{p}{[}\PY{n}{remaining\PYZus{}predictors}\PY{p}{]}
            \PY{n}{subset\PYZus{}X\PYZus{}test} \PY{o}{=} \PY{n}{X\PYZus{}test}\PY{p}{[}\PY{n}{remaining\PYZus{}predictors}\PY{p}{]}

            \PY{n}{model} \PY{o}{=} \PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{subset\PYZus{}X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
            \PY{n}{predictions} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{subset\PYZus{}X\PYZus{}test}\PY{p}{)}
            \PY{n}{mse} \PY{o}{=} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{predictions}\PY{p}{)}

            \PY{k}{if} \PY{n}{mse} \PY{o}{\PYZlt{}} \PY{n}{best\PYZus{}mse}\PY{p}{:}
                \PY{n}{best\PYZus{}mse} \PY{o}{=} \PY{n}{mse}
                \PY{n}{best\PYZus{}subset} \PY{o}{=} \PY{n}{remaining\PYZus{}predictors}
        
        \PY{k}{if} \PY{n}{best\PYZus{}subset}\PY{p}{:}
            \PY{n}{selected\PYZus{}predictors} \PY{o}{=} \PY{n}{best\PYZus{}subset}
    
    \PY{k}{return} \PY{n}{selected\PYZus{}predictors}\PY{p}{,} \PY{n}{best\PYZus{}mse}

\PY{n}{backward\PYZus{}selected\PYZus{}predictors}\PY{p}{,} \PY{n}{backward\PYZus{}best\PYZus{}mse} \PY{o}{=} \PY{n}{backward\PYZus{}stepwise\PYZus{}selection}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{predictors}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Backward Stepwise Selection Predictors: }\PY{l+s+si}{\PYZob{}}\PY{n}{backward\PYZus{}selected\PYZus{}predictors}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Test Error (MSE) for Backward Stepwise Selection: }\PY{l+s+si}{\PYZob{}}\PY{n}{backward\PYZus{}best\PYZus{}mse}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Forward Stepwise Selection Predictors: ['income\_composition\_resources',
'hiv\_aids', 'adult\_mortality', 'bmi', 'diphtheria', 'percentage\_expenditure',
'polio']
Test Error (MSE) for Forward Stepwise Selection: 13.624697136527905
Backward Stepwise Selection Predictors: ['hiv\_aids', 'schooling',
'under\_five\_deaths', 'diphtheria', 'bmi', 'percentage\_expenditure',
'income\_composition\_resources', 'adult\_mortality']
Test Error (MSE) for Backward Stepwise Selection: 13.639252315189907
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{22}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Lasso and Ridge Regression Models }

\PY{c+c1}{\PYZsh{} Initialize scaler}
\PY{n}{scaler} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Fit scaler on train data and transform both train and test set}
\PY{n}{X\PYZus{}train\PYZus{}scaled} \PY{o}{=} \PY{n}{scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}
\PY{n}{X\PYZus{}test\PYZus{}scaled} \PY{o}{=} \PY{n}{scaler}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Lasso with CV and Feature Scaling}
\PY{n}{lasso\PYZus{}params} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{alpha}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{logspace}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{9}\PY{p}{)}\PY{p}{\PYZcb{}}
\PY{n}{lasso\PYZus{}model} \PY{o}{=} \PY{n}{LassoCV}\PY{p}{(}\PY{n}{alphas}\PY{o}{=}\PY{n}{lasso\PYZus{}params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{alpha}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}
\PY{n}{lasso\PYZus{}model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}scaled}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
\PY{n}{lasso\PYZus{}pred} \PY{o}{=} \PY{n}{lasso\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}scaled}\PY{p}{)}
\PY{n}{lasso\PYZus{}mse} \PY{o}{=} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{lasso\PYZus{}pred}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Lasso Regression Best Alpha: }\PY{l+s+si}{\PYZob{}}\PY{n}{lasso\PYZus{}model}\PY{o}{.}\PY{n}{alpha\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Test Error (MSE) for Lasso Regression: }\PY{l+s+si}{\PYZob{}}\PY{n}{lasso\PYZus{}mse}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Get Lasso Coefficients}
\PY{n}{lasso\PYZus{}coefs} \PY{o}{=} \PY{n}{lasso\PYZus{}model}\PY{o}{.}\PY{n}{coef\PYZus{}}

\PY{c+c1}{\PYZsh{} Print Lasso Coefficients}
\PY{n}{sorted\PYZus{}lasso\PYZus{}coefs} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n+nb}{zip}\PY{p}{(}\PY{n}{predictors}\PY{p}{,} \PY{n}{lasso\PYZus{}coefs}\PY{p}{)}\PY{p}{,} \PY{n}{key}\PY{o}{=}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n+nb}{abs}\PY{p}{(}\PY{n}{x}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{reverse}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Lasso Coefficients:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{k}{for} \PY{n}{feature}\PY{p}{,} \PY{n}{coef} \PY{o+ow}{in} \PY{n}{sorted\PYZus{}lasso\PYZus{}coefs}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{feature}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{: }\PY{l+s+si}{\PYZob{}}\PY{n}{coef}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Ridge with CV and Feature Scaling}
\PY{n}{ridge\PYZus{}params} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{alpha}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{logspace}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{9}\PY{p}{)}\PY{p}{\PYZcb{}}
\PY{n}{ridge\PYZus{}model} \PY{o}{=} \PY{n}{RidgeCV}\PY{p}{(}\PY{n}{alphas}\PY{o}{=}\PY{n}{ridge\PYZus{}params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{alpha}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}
\PY{n}{ridge\PYZus{}model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}scaled}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
\PY{n}{ridge\PYZus{}pred} \PY{o}{=} \PY{n}{ridge\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}scaled}\PY{p}{)}
\PY{n}{ridge\PYZus{}mse} \PY{o}{=} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{ridge\PYZus{}pred}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Ridge Regression Best Alpha: }\PY{l+s+si}{\PYZob{}}\PY{n}{ridge\PYZus{}model}\PY{o}{.}\PY{n}{alpha\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Test Error (MSE) for Ridge Regression: }\PY{l+s+si}{\PYZob{}}\PY{n}{ridge\PYZus{}mse}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Get Ridge Coefficients}
\PY{n}{ridge\PYZus{}coefs} \PY{o}{=} \PY{n}{ridge\PYZus{}model}\PY{o}{.}\PY{n}{coef\PYZus{}}

\PY{c+c1}{\PYZsh{} Print Ridge Coefficients}
\PY{n}{sorted\PYZus{}ridge\PYZus{}coefs} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n+nb}{zip}\PY{p}{(}\PY{n}{predictors}\PY{p}{,} \PY{n}{ridge\PYZus{}coefs}\PY{p}{)}\PY{p}{,} \PY{n}{key}\PY{o}{=}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n+nb}{abs}\PY{p}{(}\PY{n}{x}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{reverse}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Ridge Coefficients:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{k}{for} \PY{n}{feature}\PY{p}{,} \PY{n}{coef} \PY{o+ow}{in} \PY{n}{sorted\PYZus{}ridge\PYZus{}coefs}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{feature}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{: }\PY{l+s+si}{\PYZob{}}\PY{n}{coef}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    
\PY{c+c1}{\PYZsh{} Extract features and coefficients}
\PY{n}{features} \PY{o}{=} \PY{p}{[}\PY{n}{feature} \PY{k}{for} \PY{n}{feature}\PY{p}{,} \PY{n}{coef} \PY{o+ow}{in} \PY{n}{sorted\PYZus{}lasso\PYZus{}coefs}\PY{p}{]}
\PY{n}{coefficients} \PY{o}{=} \PY{p}{[}\PY{n}{coef} \PY{k}{for} \PY{n}{feature}\PY{p}{,} \PY{n}{coef} \PY{o+ow}{in} \PY{n}{sorted\PYZus{}lasso\PYZus{}coefs}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Plot Lasso coefficients}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
\PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{coefficients}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{features}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{skyblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Lasso Regression Coefficients}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Coefficient Value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predictor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Extract features and coefficients for Ridge Regression}
\PY{n}{ridge\PYZus{}features} \PY{o}{=} \PY{p}{[}\PY{n}{feature} \PY{k}{for} \PY{n}{feature}\PY{p}{,} \PY{n}{coef} \PY{o+ow}{in} \PY{n}{sorted\PYZus{}ridge\PYZus{}coefs}\PY{p}{]}
\PY{n}{ridge\PYZus{}coefficients} \PY{o}{=} \PY{p}{[}\PY{n}{coef} \PY{k}{for} \PY{n}{feature}\PY{p}{,} \PY{n}{coef} \PY{o+ow}{in} \PY{n}{sorted\PYZus{}ridge\PYZus{}coefs}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Plot Ridge Regression coefficients}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
\PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{ridge\PYZus{}coefficients}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{ridge\PYZus{}features}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{skyblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Ridge Regression Coefficients}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Coefficient Value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predictor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Lasso Regression Best Alpha: 0.01
Test Error (MSE) for Lasso Regression: 13.895711091324577
Lasso Coefficients:
bmi: -2.2434612232196884
polio: 0.698721763941445
under\_five\_deaths: -0.6465963777816681
hiv\_aids: 0.5743211805680589
percentage\_expenditure: 0.3362297706715429
schooling: -0.3085431958482918
income\_composition\_resources: 0.2396820622240113
diphtheria: -0.2305580112219805
adult\_mortality: 0.0
Ridge Regression Best Alpha: 100.0
Test Error (MSE) for Ridge Regression: 13.843180968055705
Ridge Coefficients:
bmi: -2.2128468574655855
hiv\_aids: 0.659022262548571
under\_five\_deaths: -0.48675012358342384
polio: 0.450570589669475
percentage\_expenditure: 0.3684517042753042
schooling: -0.31567817309625473
income\_composition\_resources: 0.27498420309674887
diphtheria: -0.19517525020260246
adult\_mortality: 0.0
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_21_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_21_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{23}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Decision Tree Model}

\PY{c+c1}{\PYZsh{} Initialize Decision Tree Regressor}
\PY{n}{tree\PYZus{}regressor} \PY{o}{=} \PY{n}{DecisionTreeRegressor}\PY{p}{(}\PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Fit model on training data}
\PY{n}{tree\PYZus{}regressor}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Make predictions on test set}
\PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{tree\PYZus{}regressor}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Evaluate the model using MSE}
\PY{n}{mse} \PY{o}{=} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mean Squared Error for Decision Tree (Before Pruning): }\PY{l+s+si}{\PYZob{}}\PY{n}{mse}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display tree }
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
\PY{n}{plot\PYZus{}tree}\PY{p}{(}\PY{n}{tree\PYZus{}regressor}\PY{p}{,} \PY{n}{feature\PYZus{}names}\PY{o}{=}\PY{n}{X}\PY{o}{.}\PY{n}{columns}\PY{p}{,} \PY{n}{filled}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{rounded}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Prune tree for optimal tree size }

\PY{c+c1}{\PYZsh{} Define parameters}
\PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}leaf\PYZus{}nodes}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{)}\PY{p}{\PYZcb{}}

\PY{c+c1}{\PYZsh{} Create decision tree regressor}
\PY{n}{tree\PYZus{}regressor\PYZus{}cv} \PY{o}{=} \PY{n}{DecisionTreeRegressor}\PY{p}{(}\PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Cross Validation}
\PY{n}{grid\PYZus{}search} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{tree\PYZus{}regressor\PYZus{}cv}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neg\PYZus{}mean\PYZus{}squared\PYZus{}error}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{grid\PYZus{}search}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print optimal tree size}
\PY{n}{best\PYZus{}tree\PYZus{}size} \PY{o}{=} \PY{n}{grid\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}leaf\PYZus{}nodes}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Optimal Tree Size:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{best\PYZus{}tree\PYZus{}size}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create a pruned tree with the optimal tree size}
\PY{n}{pruned\PYZus{}tree} \PY{o}{=} \PY{n}{DecisionTreeRegressor}\PY{p}{(}\PY{n}{max\PYZus{}leaf\PYZus{}nodes}\PY{o}{=}\PY{n}{best\PYZus{}tree\PYZus{}size}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
\PY{n}{pruned\PYZus{}tree}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Make predictions on the test set}
\PY{n}{y\PYZus{}pred\PYZus{}pruned} \PY{o}{=} \PY{n}{pruned\PYZus{}tree}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Evaluate the pruned tree using MSE}
\PY{n}{mse\PYZus{}pruned} \PY{o}{=} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred\PYZus{}pruned}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mean Squared Error For Decision Tree (Pruned): }\PY{l+s+si}{\PYZob{}}\PY{n}{mse\PYZus{}pruned}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display Pruned Tree}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
\PY{n}{plot\PYZus{}tree}\PY{p}{(}\PY{n}{pruned\PYZus{}tree}\PY{p}{,} \PY{n}{feature\PYZus{}names}\PY{o}{=}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{columns}\PY{p}{,} \PY{n}{filled}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{rounded}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display Pruned Tree Structure}
\PY{n}{tree\PYZus{}structure\PYZus{}pruned} \PY{o}{=} \PY{n}{export\PYZus{}text}\PY{p}{(}\PY{n}{pruned\PYZus{}tree}\PY{p}{,} \PY{n}{feature\PYZus{}names}\PY{o}{=}\PY{n+nb}{list}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{columns}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Decision Tree Structure (Pruned):}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{tree\PYZus{}structure\PYZus{}pruned}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display Un\PYZhy{}Pruned Tree Information}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Original Decision Tree Information:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of nodes in the original tree:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{tree\PYZus{}regressor}\PY{o}{.}\PY{n}{tree\PYZus{}}\PY{o}{.}\PY{n}{node\PYZus{}count}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Depth of the original tree:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{tree\PYZus{}regressor}\PY{o}{.}\PY{n}{get\PYZus{}depth}\PY{p}{(}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display Pruned Tree Information}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Pruned Decision Tree Information:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of nodes in the pruned tree:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{pruned\PYZus{}tree}\PY{o}{.}\PY{n}{tree\PYZus{}}\PY{o}{.}\PY{n}{node\PYZus{}count}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Depth of the pruned tree:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{pruned\PYZus{}tree}\PY{o}{.}\PY{n}{get\PYZus{}depth}\PY{p}{(}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Get feature importances from pruned tree}
\PY{n}{feature\PYZus{}importances\PYZus{}pruned} \PY{o}{=} \PY{n}{pruned\PYZus{}tree}\PY{o}{.}\PY{n}{feature\PYZus{}importances\PYZus{}}

\PY{n}{feature\PYZus{}importance\PYZus{}pruned\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{X}\PY{o}{.}\PY{n}{columns}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{feature\PYZus{}importances\PYZus{}pruned}\PY{p}{\PYZcb{}}\PY{p}{)}
\PY{n}{feature\PYZus{}importance\PYZus{}pruned\PYZus{}df} \PY{o}{=} \PY{n}{feature\PYZus{}importance\PYZus{}pruned\PYZus{}df}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display feature importances}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Feature Importances of Pruned Tree:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{feature\PYZus{}importance\PYZus{}pruned\PYZus{}df}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create a df}
\PY{n}{feature\PYZus{}importance\PYZus{}pruned\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{X}\PY{o}{.}\PY{n}{columns}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{feature\PYZus{}importances\PYZus{}pruned}\PY{p}{\PYZcb{}}\PY{p}{)}
\PY{n}{feature\PYZus{}importance\PYZus{}pruned\PYZus{}df} \PY{o}{=} \PY{n}{feature\PYZus{}importance\PYZus{}pruned\PYZus{}df}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot Importances}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
\PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{feature\PYZus{}importance\PYZus{}pruned\PYZus{}df}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{skyblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature Importances of Pruned Decision Tree}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Mean Squared Error for Decision Tree (Before Pruning): 8.628424242424243
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_22_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Optimal Tree Size: 62
Mean Squared Error For Decision Tree (Pruned): 8.447601596001256
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_22_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]

Decision Tree Structure (Pruned):
 |--- income\_composition\_resources <= 0.56
|   |--- hiv\_aids <= 1.65
|   |   |--- adult\_mortality <= 248.00
|   |   |   |--- schooling <= 12.25
|   |   |   |   |--- schooling <= 7.85
|   |   |   |   |   |--- total\_expenditure <= 0.06
|   |   |   |   |   |   |--- value: [63.96]
|   |   |   |   |   |--- total\_expenditure >  0.06
|   |   |   |   |   |   |--- value: [59.42]
|   |   |   |   |--- schooling >  7.85
|   |   |   |   |   |--- adult\_mortality <= 197.50
|   |   |   |   |   |   |--- hiv\_aids <= 0.25
|   |   |   |   |   |   |   |--- value: [68.18]
|   |   |   |   |   |   |--- hiv\_aids >  0.25
|   |   |   |   |   |   |   |--- value: [65.11]
|   |   |   |   |   |--- adult\_mortality >  197.50
|   |   |   |   |   |   |--- value: [64.51]
|   |   |   |--- schooling >  12.25
|   |   |   |   |--- alcohol <= 1.21
|   |   |   |   |   |--- value: [68.15]
|   |   |   |   |--- alcohol >  1.21
|   |   |   |   |   |--- value: [73.59]
|   |   |--- adult\_mortality >  248.00
|   |   |   |--- adult\_mortality <= 373.50
|   |   |   |   |--- under\_five\_deaths <= 59.00
|   |   |   |   |   |--- bmi <= 16.90
|   |   |   |   |   |   |--- value: [63.49]
|   |   |   |   |   |--- bmi >  16.90
|   |   |   |   |   |   |--- value: [60.83]
|   |   |   |   |--- under\_five\_deaths >  59.00
|   |   |   |   |   |--- value: [58.32]
|   |   |   |--- adult\_mortality >  373.50
|   |   |   |   |--- value: [48.70]
|   |--- hiv\_aids >  1.65
|   |   |--- hiv\_aids <= 16.10
|   |   |   |--- adult\_mortality <= 359.50
|   |   |   |   |--- income\_composition\_resources <= 0.52
|   |   |   |   |   |--- under\_five\_deaths <= 32.00
|   |   |   |   |   |   |--- thinness\_5\_to\_19\_years <= 0.13
|   |   |   |   |   |   |   |--- value: [62.43]
|   |   |   |   |   |   |--- thinness\_5\_to\_19\_years >  0.13
|   |   |   |   |   |   |   |--- value: [58.19]
|   |   |   |   |   |--- under\_five\_deaths >  32.00
|   |   |   |   |   |   |--- total\_expenditure <= 0.01
|   |   |   |   |   |   |   |--- value: [45.30]
|   |   |   |   |   |   |--- total\_expenditure >  0.01
|   |   |   |   |   |   |   |--- country\_population <= 34608812.00
|   |   |   |   |   |   |   |   |--- value: [56.05]
|   |   |   |   |   |   |   |--- country\_population >  34608812.00
|   |   |   |   |   |   |   |   |--- alcohol <= 5.71
|   |   |   |   |   |   |   |   |   |--- total\_expenditure <= 0.04
|   |   |   |   |   |   |   |   |   |   |--- value: [58.85]
|   |   |   |   |   |   |   |   |   |--- total\_expenditure >  0.04
|   |   |   |   |   |   |   |   |   |   |--- value: [65.50]
|   |   |   |   |   |   |   |   |--- alcohol >  5.71
|   |   |   |   |   |   |   |   |   |--- value: [49.20]
|   |   |   |   |--- income\_composition\_resources >  0.52
|   |   |   |   |   |--- hiv\_aids <= 2.15
|   |   |   |   |   |   |--- value: [68.67]
|   |   |   |   |   |--- hiv\_aids >  2.15
|   |   |   |   |   |   |--- value: [61.78]
|   |   |   |--- adult\_mortality >  359.50
|   |   |   |   |--- thinness\_5\_to\_19\_years <= 0.17
|   |   |   |   |   |--- adult\_mortality <= 442.00
|   |   |   |   |   |   |--- schooling <= 10.15
|   |   |   |   |   |   |   |--- value: [54.21]
|   |   |   |   |   |   |--- schooling >  10.15
|   |   |   |   |   |   |   |--- value: [57.37]
|   |   |   |   |   |--- adult\_mortality >  442.00
|   |   |   |   |   |   |--- value: [52.35]
|   |   |   |   |--- thinness\_5\_to\_19\_years >  0.17
|   |   |   |   |   |--- hiv\_aids <= 2.85
|   |   |   |   |   |   |--- value: [48.53]
|   |   |   |   |   |--- hiv\_aids >  2.85
|   |   |   |   |   |   |--- value: [51.91]
|   |   |--- hiv\_aids >  16.10
|   |   |   |--- value: [46.62]
|--- income\_composition\_resources >  0.56
|   |--- income\_composition\_resources <= 0.80
|   |   |--- adult\_mortality <= 216.50
|   |   |   |--- income\_composition\_resources <= 0.70
|   |   |   |   |--- total\_expenditure <= 0.03
|   |   |   |   |   |--- value: [67.29]
|   |   |   |   |--- total\_expenditure >  0.03
|   |   |   |   |   |--- hiv\_aids <= 3.45
|   |   |   |   |   |   |--- adult\_mortality <= 175.50
|   |   |   |   |   |   |   |--- percentage\_expenditure <= 10.29
|   |   |   |   |   |   |   |   |--- total\_expenditure <= 0.11
|   |   |   |   |   |   |   |   |   |--- alcohol <= 7.00
|   |   |   |   |   |   |   |   |   |   |--- thinness\_5\_to\_19\_years <= 0.30
|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3
|   |   |   |   |   |   |   |   |   |   |--- thinness\_5\_to\_19\_years >  0.30
|   |   |   |   |   |   |   |   |   |   |   |--- value: [67.63]
|   |   |   |   |   |   |   |   |   |--- alcohol >  7.00
|   |   |   |   |   |   |   |   |   |   |--- value: [65.50]
|   |   |   |   |   |   |   |   |--- total\_expenditure >  0.11
|   |   |   |   |   |   |   |   |   |--- value: [65.15]
|   |   |   |   |   |   |   |--- percentage\_expenditure >  10.29
|   |   |   |   |   |   |   |   |--- value: [77.75]
|   |   |   |   |   |   |--- adult\_mortality >  175.50
|   |   |   |   |   |   |   |--- thinness\_5\_to\_19\_years <= 0.05
|   |   |   |   |   |   |   |   |--- thinness\_5\_to\_19\_years <= 0.01
|   |   |   |   |   |   |   |   |   |--- value: [65.00]
|   |   |   |   |   |   |   |   |--- thinness\_5\_to\_19\_years >  0.01
|   |   |   |   |   |   |   |   |   |--- value: [72.71]
|   |   |   |   |   |   |   |--- thinness\_5\_to\_19\_years >  0.05
|   |   |   |   |   |   |   |   |--- alcohol <= 4.29
|   |   |   |   |   |   |   |   |   |--- value: [67.48]
|   |   |   |   |   |   |   |   |--- alcohol >  4.29
|   |   |   |   |   |   |   |   |   |--- value: [70.54]
|   |   |   |   |   |--- hiv\_aids >  3.45
|   |   |   |   |   |   |--- value: [61.43]
|   |   |   |--- income\_composition\_resources >  0.70
|   |   |   |   |--- thinness\_5\_to\_19\_years <= 0.05
|   |   |   |   |   |--- adult\_mortality <= 127.50
|   |   |   |   |   |   |--- total\_expenditure <= 0.08
|   |   |   |   |   |   |   |--- value: [75.87]
|   |   |   |   |   |   |--- total\_expenditure >  0.08
|   |   |   |   |   |   |   |--- value: [77.52]
|   |   |   |   |   |--- adult\_mortality >  127.50
|   |   |   |   |   |   |--- value: [73.92]
|   |   |   |   |--- thinness\_5\_to\_19\_years >  0.05
|   |   |   |   |   |--- adult\_mortality <= 177.50
|   |   |   |   |   |   |--- alcohol <= 9.77
|   |   |   |   |   |   |   |--- value: [73.71]
|   |   |   |   |   |   |--- alcohol >  9.77
|   |   |   |   |   |   |   |--- percentage\_expenditure <= 0.19
|   |   |   |   |   |   |   |   |--- value: [65.75]
|   |   |   |   |   |   |   |--- percentage\_expenditure >  0.19
|   |   |   |   |   |   |   |   |--- value: [71.73]
|   |   |   |   |   |--- adult\_mortality >  177.50
|   |   |   |   |   |   |--- value: [71.07]
|   |   |--- adult\_mortality >  216.50
|   |   |   |--- adult\_mortality <= 371.00
|   |   |   |   |--- bmi <= 55.35
|   |   |   |   |   |--- adult\_mortality <= 262.50
|   |   |   |   |   |   |--- value: [66.74]
|   |   |   |   |   |--- adult\_mortality >  262.50
|   |   |   |   |   |   |--- value: [63.59]
|   |   |   |   |--- bmi >  55.35
|   |   |   |   |   |--- schooling <= 15.45
|   |   |   |   |   |   |--- value: [68.96]
|   |   |   |   |   |--- schooling >  15.45
|   |   |   |   |   |   |--- value: [74.33]
|   |   |   |--- adult\_mortality >  371.00
|   |   |   |   |--- adult\_mortality <= 575.00
|   |   |   |   |   |--- value: [55.71]
|   |   |   |   |--- adult\_mortality >  575.00
|   |   |   |   |   |--- value: [47.25]
|   |--- income\_composition\_resources >  0.80
|   |   |--- thinness\_5\_to\_19\_years <= 0.04
|   |   |   |--- adult\_mortality <= 80.00
|   |   |   |   |--- adult\_mortality <= 67.50
|   |   |   |   |   |--- total\_expenditure <= 0.08
|   |   |   |   |   |   |--- income\_composition\_resources <= 0.88
|   |   |   |   |   |   |   |--- value: [78.44]
|   |   |   |   |   |   |--- income\_composition\_resources >  0.88
|   |   |   |   |   |   |   |--- value: [81.61]
|   |   |   |   |   |--- total\_expenditure >  0.08
|   |   |   |   |   |   |--- value: [82.05]
|   |   |   |   |--- adult\_mortality >  67.50
|   |   |   |   |   |--- alcohol <= 9.86
|   |   |   |   |   |   |--- bmi <= 60.35
|   |   |   |   |   |   |   |--- value: [80.33]
|   |   |   |   |   |   |--- bmi >  60.35
|   |   |   |   |   |   |   |--- value: [83.78]
|   |   |   |   |   |--- alcohol >  9.86
|   |   |   |   |   |   |--- total\_expenditure <= 0.11
|   |   |   |   |   |   |   |--- value: [85.28]
|   |   |   |   |   |   |--- total\_expenditure >  0.11
|   |   |   |   |   |   |   |--- value: [81.30]
|   |   |   |--- adult\_mortality >  80.00
|   |   |   |   |--- percentage\_expenditure <= 0.69
|   |   |   |   |   |--- value: [89.00]
|   |   |   |   |--- percentage\_expenditure >  0.69
|   |   |   |   |   |--- value: [79.54]
|   |   |--- thinness\_5\_to\_19\_years >  0.04
|   |   |   |--- value: [74.09]

Original Decision Tree Information:
Number of nodes in the original tree: 2351
Depth of the original tree: 29

Pruned Decision Tree Information:
Number of nodes in the pruned tree: 123
Depth of the pruned tree: 13
Feature Importances of Pruned Tree:
                         Feature  Importance
16  income\_composition\_resources    0.689602
2                adult\_mortality    0.129980
12                      hiv\_aids    0.119355
14        thinness\_5\_to\_19\_years    0.022546
10             total\_expenditure    0.011108
15                     schooling    0.008734
3                        alcohol    0.006877
6                            bmi    0.004306
7              under\_five\_deaths    0.003819
4         percentage\_expenditure    0.002594
13            country\_population    0.001078
0                          const    0.000000
11                    diphtheria    0.000000
9                    country\_gdp    0.000000
1                         status    0.000000
5                    hepatitis\_b    0.000000
8                          polio    0.000000
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_22_5.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{24}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Random Forest Model}

\PY{c+c1}{\PYZsh{} Initialize Random Forest Regressor}
\PY{n}{random\PYZus{}forest\PYZus{}model} \PY{o}{=} \PY{n}{RandomForestRegressor}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Fit model on training data}
\PY{n}{random\PYZus{}forest\PYZus{}model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Predict on test set}
\PY{n}{y\PYZus{}pred\PYZus{}rf} \PY{o}{=} \PY{n}{random\PYZus{}forest\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Calculate test MSE for Random Forest}
\PY{n}{test\PYZus{}mse\PYZus{}rf} \PY{o}{=} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred\PYZus{}rf}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Test MSE for Random Forest:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{test\PYZus{}mse\PYZus{}rf}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Determine feature importances}
\PY{n}{feature\PYZus{}importances\PYZus{}rf} \PY{o}{=} \PY{n}{random\PYZus{}forest\PYZus{}model}\PY{o}{.}\PY{n}{feature\PYZus{}importances\PYZus{}}
\PY{n}{feature\PYZus{}importance\PYZus{}rf} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{columns}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{feature\PYZus{}importances\PYZus{}rf}\PY{p}{\PYZcb{}}\PY{p}{)}
\PY{n}{feature\PYZus{}importance\PYZus{}rf} \PY{o}{=} \PY{n}{feature\PYZus{}importance\PYZus{}rf}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display feature importances}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Feature Importance:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{feature\PYZus{}importance\PYZus{}rf}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Test MSE for Random Forest: 3.5643493545454628
Feature Importance:
                         Feature  Importance
16  income\_composition\_resources    0.607003
12                      hiv\_aids    0.182911
2                adult\_mortality    0.125515
14        thinness\_5\_to\_19\_years    0.023084
10             total\_expenditure    0.010435
15                     schooling    0.010107
3                        alcohol    0.008716
7              under\_five\_deaths    0.006283
6                            bmi    0.005759
4         percentage\_expenditure    0.003997
9                    country\_gdp    0.003745
13            country\_population    0.003543
8                          polio    0.003443
11                    diphtheria    0.002787
5                    hepatitis\_b    0.002544
1                         status    0.000127
0                          const    0.000000
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{25}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Bagging Model}

\PY{c+c1}{\PYZsh{} Initialize base regressor. Decision tree regressor used here instead of gradient, as the decision tree regressor performs better. This is perhaps due to possible overfitting of gradient boosting regressor}
\PY{n}{base\PYZus{}regressor} \PY{o}{=} \PY{n}{DecisionTreeRegressor}\PY{p}{(}\PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Initialize bagging regressor}
\PY{n}{bagging\PYZus{}regressor} \PY{o}{=} \PY{n}{BaggingRegressor}\PY{p}{(}\PY{n}{base\PYZus{}regressor}\PY{p}{,} \PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Fit bagging regression to the training set}
\PY{n}{bagging\PYZus{}regressor}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Predict on the test set}
\PY{n}{bagging\PYZus{}preds} \PY{o}{=} \PY{n}{bagging\PYZus{}regressor}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Calculate test set MSE}
\PY{n}{bagging\PYZus{}mse} \PY{o}{=} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{bagging\PYZus{}preds}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print test set MSE for bagging}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Test Set MSE for Bagging: }\PY{l+s+si}{\PYZob{}}\PY{n}{bagging\PYZus{}mse}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}


\PY{c+c1}{\PYZsh{} Find feature importances, average all base estimators together and display list}

\PY{c+c1}{\PYZsh{} Get the list of base estimators fitted by bagging regressor}
\PY{n}{base\PYZus{}estimators} \PY{o}{=} \PY{n}{bagging\PYZus{}regressor}\PY{o}{.}\PY{n}{estimators\PYZus{}}

\PY{c+c1}{\PYZsh{} Initialize an array for base estimator storage}
\PY{n}{all\PYZus{}feature\PYZus{}importances} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{base\PYZus{}estimators}\PY{p}{)}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Iterate through each base estimator and get feature importances}
\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{base\PYZus{}estimator} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{base\PYZus{}estimators}\PY{p}{)}\PY{p}{:}
    \PY{n}{all\PYZus{}feature\PYZus{}importances}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{p}{:}\PY{p}{]} \PY{o}{=} \PY{n}{base\PYZus{}estimator}\PY{o}{.}\PY{n}{feature\PYZus{}importances\PYZus{}}

\PY{c+c1}{\PYZsh{} Calculate mean importance across all iterations}
\PY{n}{mean\PYZus{}feature\PYZus{}importances} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{all\PYZus{}feature\PYZus{}importances}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}

\PY{n}{feature\PYZus{}importance\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{X}\PY{o}{.}\PY{n}{columns}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean\PYZus{}Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{mean\PYZus{}feature\PYZus{}importances}\PY{p}{\PYZcb{}}\PY{p}{)}
\PY{n}{feature\PYZus{}importance\PYZus{}df} \PY{o}{=} \PY{n}{feature\PYZus{}importance\PYZus{}df}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean\PYZus{}Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display mean feature importances}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mean Feature Importances for Bagging:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{feature\PYZus{}importance\PYZus{}df}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot Feature Importances}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}
\PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean\PYZus{}Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{feature\PYZus{}importance\PYZus{}df}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{skyblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Feature Importances for Bagging Model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Test Set MSE for Bagging: 3.676756909090907
Mean Feature Importances for Bagging:
                         Feature  Mean\_Importance
16  income\_composition\_resources         0.601978
12                      hiv\_aids         0.184755
2                adult\_mortality         0.129262
14        thinness\_5\_to\_19\_years         0.022835
10             total\_expenditure         0.010366
15                     schooling         0.010257
3                        alcohol         0.008608
7              under\_five\_deaths         0.005798
6                            bmi         0.005739
4         percentage\_expenditure         0.004233
9                    country\_gdp         0.003830
13            country\_population         0.003514
8                          polio         0.003494
11                    diphtheria         0.002770
5                    hepatitis\_b         0.002471
1                         status         0.000091
0                          const         0.000000
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_24_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{26}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Boosting Model}

\PY{c+c1}{\PYZsh{} Initialize the boosting regressor}
\PY{n}{boost\PYZus{}regressor} \PY{o}{=} \PY{n}{GradientBoostingRegressor}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Fit the boosting model on the training data}
\PY{n}{boost\PYZus{}regressor}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Predict on the test set}
\PY{n}{y\PYZus{}pred\PYZus{}boost} \PY{o}{=} \PY{n}{boost\PYZus{}regressor}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Calculate the test MSE}
\PY{n}{test\PYZus{}mse\PYZus{}boost} \PY{o}{=} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred\PYZus{}boost}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Test Error (MSE) for Boosting :}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{test\PYZus{}mse\PYZus{}boost}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Get feature importances}
\PY{n}{feature\PYZus{}importance} \PY{o}{=} \PY{n}{boost\PYZus{}regressor}\PY{o}{.}\PY{n}{feature\PYZus{}importances\PYZus{}}

\PY{n}{feature\PYZus{}importance\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{columns}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{feature\PYZus{}importance}\PY{p}{\PYZcb{}}\PY{p}{)}
\PY{n}{feature\PYZus{}importance\PYZus{}df} \PY{o}{=} \PY{n}{feature\PYZus{}importance\PYZus{}df}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print feature importance}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Feature Importances for Boosting:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{feature\PYZus{}importance\PYZus{}df}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot Feature Importances}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
\PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{feature\PYZus{}importance\PYZus{}df}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{skyblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature Importances for Boosting Model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Test Error (MSE) for Boosting : 5.017524037267107
Feature Importances for Boosting:
                         Feature  Importance
16  income\_composition\_resources    0.549505
12                      hiv\_aids    0.235133
2                adult\_mortality    0.140226
14        thinness\_5\_to\_19\_years    0.033077
7              under\_five\_deaths    0.011768
15                     schooling    0.007011
3                        alcohol    0.005941
10             total\_expenditure    0.005557
4         percentage\_expenditure    0.003669
6                            bmi    0.002548
13            country\_population    0.001523
8                          polio    0.001245
11                    diphtheria    0.001240
9                    country\_gdp    0.000955
5                    hepatitis\_b    0.000444
1                         status    0.000160
0                          const    0.000000
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_25_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{27}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Partial Least Squares Model}

\PY{c+c1}{\PYZsh{} Initialize PLS regression model}
\PY{n}{pls\PYZus{}regressor} \PY{o}{=} \PY{n}{PLSRegression}\PY{p}{(}\PY{n}{n\PYZus{}components}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Fit the PLS model on the training data}
\PY{n}{pls\PYZus{}regressor}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Predict on the test set}
\PY{n}{y\PYZus{}pred\PYZus{}pls} \PY{o}{=} \PY{n}{pls\PYZus{}regressor}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Calculate the test MSE}
\PY{n}{test\PYZus{}mse\PYZus{}pls} \PY{o}{=} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred\PYZus{}pls}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PLS Test MSE:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{test\PYZus{}mse\PYZus{}pls}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Find Absolute Mean of each feature in the model and list in descending order}

\PY{c+c1}{\PYZsh{} Get Loadings}
\PY{n}{loadings} \PY{o}{=} \PY{n}{pls\PYZus{}regressor}\PY{o}{.}\PY{n}{x\PYZus{}loadings\PYZus{}}

\PY{c+c1}{\PYZsh{} Define feature names and put in df}
\PY{n}{feature\PYZus{}names} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{columns}\PY{p}{)}
\PY{n}{n\PYZus{}components} \PY{o}{=} \PY{l+m+mi}{3} 
\PY{n}{loadings\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{loadings}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Component\PYZus{}}\PY{l+s+si}{\PYZob{}}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{n\PYZus{}components}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{n}{loadings\PYZus{}df}\PY{o}{.}\PY{n}{index} \PY{o}{=} \PY{n}{feature\PYZus{}names}

\PY{c+c1}{\PYZsh{} Calculate absolute mean for each feature}
\PY{n}{loadings\PYZus{}df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Absolute\PYZus{}Mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{loadings\PYZus{}df}\PY{o}{.}\PY{n}{abs}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Sort df by absolute mean in descending order}
\PY{n}{loadings\PYZus{}df} \PY{o}{=} \PY{n}{loadings\PYZus{}df}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Absolute\PYZus{}Mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display Loadings}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{loadings\PYZus{}df}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
PLS Test MSE: 13.847597559123793
                              Component\_1  Component\_2  Component\_3  \textbackslash{}
under\_five\_deaths               -0.139352    -0.232765    -0.687548
country\_population              -0.044013    -0.228999    -0.730638
alcohol                          0.292114     0.301698    -0.330864
hiv\_aids                        -0.194359     0.580887    -0.070790
adult\_mortality                 -0.284462     0.463528    -0.011021
total\_expenditure                0.138540     0.235638     0.338624
status                           0.293845     0.209124    -0.200710
schooling                        0.385298     0.048440     0.152277
country\_gdp                      0.288171     0.241973     0.028085
percentage\_expenditure           0.273866     0.246192     0.030274
bmi                              0.292712    -0.038532    -0.201162
polio                            0.203526     0.121874    -0.166183
income\_composition\_resources     0.366462    -0.023188     0.099598
diphtheria                       0.214479     0.121224    -0.143546
hepatitis\_b                      0.145007     0.148748    -0.141164
thinness\_5\_to\_19\_years          -0.285279    -0.101390     0.013115
const                            0.000000     0.000000     0.000000

                              Absolute\_Mean
under\_five\_deaths                  0.353222
country\_population                 0.334550
alcohol                            0.308225
hiv\_aids                           0.282012
adult\_mortality                    0.253004
total\_expenditure                  0.237601
status                             0.234559
schooling                          0.195338
country\_gdp                        0.186077
percentage\_expenditure             0.183444
bmi                                0.177468
polio                              0.163861
income\_composition\_resources       0.163083
diphtheria                         0.159750
hepatitis\_b                        0.144973
thinness\_5\_to\_19\_years             0.133261
const                              0.000000
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{28}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Principal Components Regression }

\PY{c+c1}{\PYZsh{} PCR with Cross\PYZhy{}Validation}
\PY{n}{pca\PYZus{}params} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pca\PYZus{}\PYZus{}n\PYZus{}components}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{predictors}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{\PYZcb{}}
\PY{n}{pca\PYZus{}model} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
    \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pca}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{PCA}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}
    \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{regression}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{p}{]}\PY{p}{)}

\PY{n}{pca\PYZus{}grid} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{pca\PYZus{}model}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{o}{=}\PY{n}{pca\PYZus{}params}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neg\PYZus{}mean\PYZus{}squared\PYZus{}error}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{pca\PYZus{}grid}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Predict using the best estimator}
\PY{n}{pcr\PYZus{}pred} \PY{o}{=} \PY{n}{pca\PYZus{}grid}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Calculate MSE}
\PY{n}{pcr\PYZus{}mse} \PY{o}{=} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{pcr\PYZus{}pred}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PCR M: }\PY{l+s+si}{\PYZob{}}\PY{n}{pca\PYZus{}grid}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pca\PYZus{}\PYZus{}n\PYZus{}components}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Test Error (MSE) for PCR: }\PY{l+s+si}{\PYZob{}}\PY{n}{pcr\PYZus{}mse}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot Predicted vs Actual Values}
\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{pcr\PYZus{}pred}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Actual Values}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Predicted Values}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PCR Predicted vs Actual Values}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
PCR M: 9
Test Error (MSE) for PCR: 15.485975939003584
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_27_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{29}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Linear Model Input}

\PY{n}{input\PYZus{}data} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{const}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{52.47}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{1}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adult\PYZus{}mortality}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{18.35}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{alcohol}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{9.5}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{percentage\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.17}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hepatitis\PYZus{}b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.92}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bmi}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{26.5}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{under\PYZus{}five\PYZus{}deaths}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{7.2}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polio}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.93}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{country\PYZus{}gdp}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{70248.63}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{total\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.29}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{diphtheria}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.80}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hiv\PYZus{}aids}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.1}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{country\PYZus{}population}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{331900000}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thinness\PYZus{}5\PYZus{}to\PYZus{}19\PYZus{}years}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.04}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{schooling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{14}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{income\PYZus{}composition\PYZus{}resources}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.921}
\PY{p}{\PYZcb{}}

\PY{c+c1}{\PYZsh{} Convert input data to df}
\PY{n}{input\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{[}\PY{n}{input\PYZus{}data}\PY{p}{]}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Make prediction linear }
\PY{n}{life\PYZus{}expectancy\PYZus{}prediction} \PY{o}{=} \PY{n}{linear\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{input\PYZus{}df}\PY{p}{)}


\PY{c+c1}{\PYZsh{} Best Subset Selection Input }

\PY{n}{best\PYZus{}subset\PYZus{}input\PYZus{}data} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adult\PYZus{}mortality}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{18.35}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{percentage\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.17}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bmi}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{26.5}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{under\PYZus{}five\PYZus{}deaths}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{7.2}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polio}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.93}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{diphtheria}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.80}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hiv\PYZus{}aids}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.1}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{schooling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{14}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{income\PYZus{}composition\PYZus{}resources}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.921}
\PY{p}{\PYZcb{}}

\PY{c+c1}{\PYZsh{} Convert input data to df}
\PY{n}{best\PYZus{}subset\PYZus{}input\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{[}\PY{n}{best\PYZus{}subset\PYZus{}input\PYZus{}data}\PY{p}{]}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Make prediction best subset}
\PY{n}{best\PYZus{}subset\PYZus{}prediction} \PY{o}{=} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{best\PYZus{}subset\PYZus{}input\PYZus{}df}\PY{p}{)}


\PY{c+c1}{\PYZsh{} Standardize the input data}
\PY{n}{input\PYZus{}scaled} \PY{o}{=} \PY{n}{scaler}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{input\PYZus{}df}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Make prediction lasso}
\PY{n}{lasso\PYZus{}prediction} \PY{o}{=} \PY{n}{lasso\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{input\PYZus{}scaled}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Make prediction ridge}
\PY{n}{ridge\PYZus{}prediction} \PY{o}{=} \PY{n}{ridge\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{input\PYZus{}scaled}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Decision Tree Model}
\PY{n}{tree\PYZus{}pred} \PY{o}{=} \PY{n}{tree\PYZus{}regressor}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{input\PYZus{}df}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Random Forest Model}
\PY{n}{rf\PYZus{}pred} \PY{o}{=} \PY{n}{random\PYZus{}forest\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{input\PYZus{}df}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Bagging Model}
\PY{n}{bagging\PYZus{}pred} \PY{o}{=} \PY{n}{bagging\PYZus{}regressor}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{input\PYZus{}df}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Boosting Model}
\PY{n}{boost\PYZus{}pred} \PY{o}{=} \PY{n}{boost\PYZus{}regressor}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{input\PYZus{}df}\PY{p}{)}

\PY{c+c1}{\PYZsh{} PLS Model}
\PY{n}{pls\PYZus{}pred} \PY{o}{=} \PY{n}{pls\PYZus{}regressor}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{input\PYZus{}df}\PY{p}{)}

\PY{c+c1}{\PYZsh{} PCR Input data in the correct order}
\PY{n}{PCR\PYZus{}input\PYZus{}data\PYZus{}ordered} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{const}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{52.47}\PY{p}{,} 
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{1}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adult\PYZus{}mortality}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{18.35}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{alcohol}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{9.5}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{percentage\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.17}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hepatitis\PYZus{}b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.92}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bmi}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{26.5}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{under\PYZus{}five\PYZus{}deaths}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{7.2}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polio}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.93}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{country\PYZus{}gdp}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{70248.63}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{total\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.29}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{diphtheria}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.80}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hiv\PYZus{}aids}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.1}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{country\PYZus{}population}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{331900000}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thinness\PYZus{}5\PYZus{}to\PYZus{}19\PYZus{}years}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.04}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{schooling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{14}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{income\PYZus{}composition\PYZus{}resources}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.921}
\PY{p}{\PYZcb{}}

\PY{c+c1}{\PYZsh{} Convert input data to df}
\PY{n}{PCR\PYZus{}input\PYZus{}df\PYZus{}ordered} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{[}\PY{n}{PCR\PYZus{}input\PYZus{}data\PYZus{}ordered}\PY{p}{]}\PY{p}{)}

\PY{c+c1}{\PYZsh{} PCR Prediction}
\PY{n}{pca\PYZus{}input\PYZus{}ordered} \PY{o}{=} \PY{n}{pca\PYZus{}grid}\PY{o}{.}\PY{n}{best\PYZus{}estimator\PYZus{}}\PY{o}{.}\PY{n}{named\PYZus{}steps}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pca}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{PCR\PYZus{}input\PYZus{}df\PYZus{}ordered}\PY{p}{)}
\PY{n}{pcr\PYZus{}pred\PYZus{}ordered} \PY{o}{=} \PY{n}{pca\PYZus{}grid}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{PCR\PYZus{}input\PYZus{}df\PYZus{}ordered}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Actual Life Expectancy in the USA 2023 is 79.11, according to macrotrends.net}
\PY{n}{actual\PYZus{}us\PYZus{}life\PYZus{}expectancy} \PY{o}{=} \PY{l+m+mf}{79.11}

\PY{c+c1}{\PYZsh{} Display Predictions}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Linear Regression Predicted Life Expectancy (USA 2023): }\PY{l+s+si}{\PYZob{}}\PY{n}{life\PYZus{}expectancy\PYZus{}prediction}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Subset Selection Predicted Life Expectancy (USA 2023): }\PY{l+s+si}{\PYZob{}}\PY{n}{best\PYZus{}subset\PYZus{}prediction}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Lasso Regression Predicted Life Expectancy (USA 2023): }\PY{l+s+si}{\PYZob{}}\PY{n}{lasso\PYZus{}prediction}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Ridge Regression Predicted Life Expectancy (USA 2023): }\PY{l+s+si}{\PYZob{}}\PY{n}{ridge\PYZus{}prediction}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Decision Tree Predicted Life Expectancy: }\PY{l+s+si}{\PYZob{}}\PY{n}{tree\PYZus{}pred}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Random Forest Predicted Life Expectancy: }\PY{l+s+si}{\PYZob{}}\PY{n}{rf\PYZus{}pred}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Bagging Predicted Life Expectancy: }\PY{l+s+si}{\PYZob{}}\PY{n}{bagging\PYZus{}pred}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Boosting Predicted Life Expectancy: }\PY{l+s+si}{\PYZob{}}\PY{n}{boost\PYZus{}pred}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PLS Predicted Life Expectancy: }\PY{l+s+si}{\PYZob{}}\PY{n}{pls\PYZus{}pred}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PCR Predicted Life Expectancy: }\PY{l+s+si}{\PYZob{}}\PY{n}{pcr\PYZus{}pred}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Calculate residual errors for each model}
\PY{n}{linear\PYZus{}regression\PYZus{}error} \PY{o}{=} \PY{n}{actual\PYZus{}us\PYZus{}life\PYZus{}expectancy} \PY{o}{\PYZhy{}} \PY{n}{life\PYZus{}expectancy\PYZus{}prediction}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\PY{n}{best\PYZus{}subset\PYZus{}error} \PY{o}{=} \PY{n}{actual\PYZus{}us\PYZus{}life\PYZus{}expectancy} \PY{o}{\PYZhy{}} \PY{n}{best\PYZus{}subset\PYZus{}prediction}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\PY{n}{lasso\PYZus{}regression\PYZus{}error} \PY{o}{=} \PY{n}{actual\PYZus{}us\PYZus{}life\PYZus{}expectancy} \PY{o}{\PYZhy{}} \PY{n}{lasso\PYZus{}prediction}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\PY{n}{ridge\PYZus{}regression\PYZus{}error} \PY{o}{=} \PY{n}{actual\PYZus{}us\PYZus{}life\PYZus{}expectancy} \PY{o}{\PYZhy{}} \PY{n}{ridge\PYZus{}prediction}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\PY{n}{decision\PYZus{}tree\PYZus{}error} \PY{o}{=} \PY{n}{actual\PYZus{}us\PYZus{}life\PYZus{}expectancy} \PY{o}{\PYZhy{}} \PY{n}{tree\PYZus{}pred}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\PY{n}{random\PYZus{}forest\PYZus{}error} \PY{o}{=} \PY{n}{actual\PYZus{}us\PYZus{}life\PYZus{}expectancy} \PY{o}{\PYZhy{}} \PY{n}{rf\PYZus{}pred}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\PY{n}{bagging\PYZus{}error} \PY{o}{=} \PY{n}{actual\PYZus{}us\PYZus{}life\PYZus{}expectancy} \PY{o}{\PYZhy{}} \PY{n}{bagging\PYZus{}pred}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\PY{n}{boosting\PYZus{}error} \PY{o}{=} \PY{n}{actual\PYZus{}us\PYZus{}life\PYZus{}expectancy} \PY{o}{\PYZhy{}} \PY{n}{boost\PYZus{}pred}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\PY{n}{pls\PYZus{}error} \PY{o}{=} \PY{n}{actual\PYZus{}us\PYZus{}life\PYZus{}expectancy} \PY{o}{\PYZhy{}} \PY{n}{pls\PYZus{}pred}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\PY{n}{pcr\PYZus{}error} \PY{o}{=} \PY{n}{actual\PYZus{}us\PYZus{}life\PYZus{}expectancy} \PY{o}{\PYZhy{}} \PY{n}{pcr\PYZus{}pred}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Create dictionary with errors}
\PY{n}{errors} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Linear Regression}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{linear\PYZus{}regression\PYZus{}error}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best Subset Selection}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{best\PYZus{}subset\PYZus{}error}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Lasso Regression}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{lasso\PYZus{}regression\PYZus{}error}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Ridge Regression}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{ridge\PYZus{}regression\PYZus{}error}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Decision Tree}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{decision\PYZus{}tree\PYZus{}error}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Random Forest}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{random\PYZus{}forest\PYZus{}error}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Bagging}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{bagging\PYZus{}error}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Boosting}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{boosting\PYZus{}error}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{PLS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{pls\PYZus{}error}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{PCR}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{pcr\PYZus{}error}\PY{p}{,}
\PY{p}{\PYZcb{}}

\PY{c+c1}{\PYZsh{} Sort order of errors}
\PY{n}{sorted\PYZus{}errors} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{errors}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{key}\PY{o}{=}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n+nb}{abs}\PY{p}{(}\PY{n}{x}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{reverse}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Display Residual Errors}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Residual Errors:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{k}{for} \PY{n}{model}\PY{p}{,} \PY{n}{error} \PY{o+ow}{in} \PY{n}{sorted\PYZus{}errors}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{model}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{: }\PY{l+s+si}{\PYZob{}}\PY{n}{error}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}


\PY{c+c1}{\PYZsh{} This data set includes WHO data from 2000 \PYZhy{} 2015. I Would like to follow the trend in each variable up to a future date, such as 2027. Then take that input data and test it in these models to predict future life expectancy}
\PY{c+c1}{\PYZsh{} I would also like to run predictions on feature value inputs from other countries to see how each model performs with different inputs.}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Linear Regression Predicted Life Expectancy (USA 2023): 79.23609149104493
Best Subset Selection Predicted Life Expectancy (USA 2023): 76.64001894885261
Lasso Regression Predicted Life Expectancy (USA 2023): 79.22946797977693
Ridge Regression Predicted Life Expectancy (USA 2023): 81.0125065636481
Decision Tree Predicted Life Expectancy: 76.3
Random Forest Predicted Life Expectancy: 75.49000000000001
Bagging Predicted Life Expectancy: 75.386
Boosting Predicted Life Expectancy: 78.29134134238686
PLS Predicted Life Expectancy: 81.37115545052427
PCR Predicted Life Expectancy: 70.10706799687415

Residual Errors:
PCR: 9.00293200312585
Bagging: 3.7240000000000038
Random Forest: 3.6199999999999903
Decision Tree: 2.8100000000000023
Best Subset Selection: 2.4699810511473856
PLS: -2.261155450524271
Ridge Regression: -1.902506563648103
Boosting: 0.8186586576131418
Linear Regression: -0.12609149104493156
Lasso Regression: -0.11946797977692825
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{30}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Principal Components Regression w/ Income Composition Resources as the Target}

\PY{c+c1}{\PYZsh{} Define predictors and target variable}
\PY{n}{predictors} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{alcohol}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{percentage\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hepatitis\PYZus{}b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bmi}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{under\PYZus{}five\PYZus{}deaths}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polio}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{total\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{diphtheria}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hiv\PYZus{}aids}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{country\PYZus{}gdp}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{country\PYZus{}population}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thinness\PYZus{}5\PYZus{}to\PYZus{}19\PYZus{}years}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adult\PYZus{}mortality}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{schooling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{life\PYZus{}expectancy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{n}{target\PYZus{}variable} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{income\PYZus{}composition\PYZus{}resources}\PY{l+s+s1}{\PYZsq{}}

\PY{n}{X} \PY{o}{=} \PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{p}{[}\PY{n}{predictors}\PY{p}{]}
\PY{n}{y} \PY{o}{=} \PY{n}{life\PYZus{}expectancy\PYZus{}df}\PY{p}{[}\PY{n}{target\PYZus{}variable}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Split data into training and testing sets}
\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}

\PY{c+c1}{\PYZsh{} PCR with Cross Validation}
\PY{n}{pca\PYZus{}params} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pca\PYZus{}\PYZus{}n\PYZus{}components}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{predictors}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{\PYZcb{}}
\PY{n}{pca\PYZus{}model} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
    \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pca}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{PCA}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}
    \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{regression}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{p}{]}\PY{p}{)}

\PY{n}{pca\PYZus{}grid} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{pca\PYZus{}model}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{o}{=}\PY{n}{pca\PYZus{}params}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neg\PYZus{}mean\PYZus{}squared\PYZus{}error}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{pca\PYZus{}grid}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Predict using the best estimator}
\PY{n}{pcr\PYZus{}pred} \PY{o}{=} \PY{n}{pca\PYZus{}grid}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Calculate MSE}
\PY{n}{pcr\PYZus{}mse} \PY{o}{=} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{pcr\PYZus{}pred}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{M: }\PY{l+s+si}{\PYZob{}}\PY{n}{pca\PYZus{}grid}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pca\PYZus{}\PYZus{}n\PYZus{}components}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Test Error (MSE) for PCR (Income Composition Resources): }\PY{l+s+si}{\PYZob{}}\PY{n}{pcr\PYZus{}mse}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Use PCR model to predict income\PYZus{}composition\PYZus{}resources given current US stastistics}
\PY{n}{icr\PYZus{}input\PYZus{}data} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{1}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{alcohol}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{9.5}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{percentage\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.17}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hepatitis\PYZus{}b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.92}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bmi}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{26.5}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{under\PYZus{}five\PYZus{}deaths}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{7.2}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polio}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.93}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{total\PYZus{}expenditure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.29}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{diphtheria}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.80}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hiv\PYZus{}aids}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.1}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{country\PYZus{}gdp}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{70248.63}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{country\PYZus{}population}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{331900000}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{thinness\PYZus{}5\PYZus{}to\PYZus{}19\PYZus{}years}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.04}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adult\PYZus{}mortality}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{18.35}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{schooling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{14}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{life\PYZus{}expectancy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{79.11} 
\PY{p}{\PYZcb{}}

\PY{c+c1}{\PYZsh{} Create df with the input data}
\PY{n}{icr\PYZus{}input\PYZus{}data\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{[}\PY{n}{icr\PYZus{}input\PYZus{}data}\PY{p}{]}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Apply PCA transformation}
\PY{n}{icr\PYZus{}pca\PYZus{}transformed\PYZus{}data} \PY{o}{=} \PY{n}{pca\PYZus{}grid}\PY{o}{.}\PY{n}{best\PYZus{}estimator\PYZus{}}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pca}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{icr\PYZus{}input\PYZus{}data\PYZus{}df}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Make prediction on target}
\PY{n}{prediction} \PY{o}{=} \PY{n}{pca\PYZus{}grid}\PY{o}{.}\PY{n}{best\PYZus{}estimator\PYZus{}}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{regression}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{icr\PYZus{}pca\PYZus{}transformed\PYZus{}data}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Predicted income\PYZus{}composition\PYZus{}resources: }\PY{l+s+si}{\PYZob{}}\PY{n}{prediction}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n}{actual\PYZus{}us\PYZus{}icr} \PY{o}{=} \PY{l+m+mf}{0.921}

\PY{c+c1}{\PYZsh{} Calculate Residual Error}
\PY{n}{residual\PYZus{}error} \PY{o}{=} \PY{n}{actual\PYZus{}us\PYZus{}icr} \PY{o}{\PYZhy{}} \PY{n}{prediction}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Print Error}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Residual Error: }\PY{l+s+si}{\PYZob{}}\PY{n}{residual\PYZus{}error}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
M: 15
Test Error (MSE) for PCR (Income Composition Resources): 0.005087865112819682
Predicted income\_composition\_resources: 0.8789390951466994
Residual Error: 0.04206090485330061
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]

\end{Verbatim}
\end{tcolorbox}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
